{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sklearn\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization,Input\nfrom keras.layers import Conv1D, Conv2D, MaxPooling2D,Conv2DTranspose,UpSampling2D\nfrom keras import regularizers, optimizers,Sequential\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport cv2\nimport keras\nfrom sklearn.metrics import recall_score\nfrom tensorflow.python.keras import backend as K \nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm_notebook\nimport os\n\n\nfrom keras.layers import Dense,GlobalAveragePooling2D\nfrom keras.applications import MobileNet\nfrom keras.preprocessing import image\nfrom keras.applications.mobilenet import preprocess_input\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        #print(os.path.join(dirname, filename))\n#        print(dirname)\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('/kaggle/')","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"['lib', 'input', 'config', 'working']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('/kaggle/input')","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"['inceptionresnetv2', 'severstal-steel-defect-detection']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('/kaggle/input/severstal-steel-defect-detection')","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"['test_images', 'train.csv', 'sample_submission.csv', 'train_images']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('/kaggle/input/severstal-steel-defect-detection/')\ndir1='/kaggle/input/severstal-steel-defect-detection/'","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(dir1+'train.csv')","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub=pd.read_csv(dir1+'sample_submission.csv')\nsub['imageid']=sub.ImageId_ClassId.apply(lambda x: x.split('_')[0])\nsub['class']=sub.ImageId_ClassId.apply(lambda x: int(x.split('_')[1]))\nprint(sub.shape)\nsub.head()\n","execution_count":7,"outputs":[{"output_type":"stream","text":"(7204, 4)\n","name":"stdout"},{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"   ImageId_ClassId EncodedPixels        imageid  class\n0  004f40c73.jpg_1           1 1  004f40c73.jpg      1\n1  004f40c73.jpg_2           1 1  004f40c73.jpg      2\n2  004f40c73.jpg_3           1 1  004f40c73.jpg      3\n3  004f40c73.jpg_4           1 1  004f40c73.jpg      4\n4  006f39c41.jpg_1           1 1  006f39c41.jpg      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId_ClassId</th>\n      <th>EncodedPixels</th>\n      <th>imageid</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>004f40c73.jpg_1</td>\n      <td>1 1</td>\n      <td>004f40c73.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>004f40c73.jpg_2</td>\n      <td>1 1</td>\n      <td>004f40c73.jpg</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>004f40c73.jpg_3</td>\n      <td>1 1</td>\n      <td>004f40c73.jpg</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>004f40c73.jpg_4</td>\n      <td>1 1</td>\n      <td>004f40c73.jpg</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>006f39c41.jpg_1</td>\n      <td>1 1</td>\n      <td>006f39c41.jpg</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.fillna(0,inplace=True)\ndf.head(3)","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"   ImageId_ClassId                                      EncodedPixels\n0  0002cc93b.jpg_1  29102 12 29346 24 29602 24 29858 24 30114 24 3...\n1  0002cc93b.jpg_2                                                  0\n2  0002cc93b.jpg_3                                                  0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId_ClassId</th>\n      <th>EncodedPixels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0002cc93b.jpg_1</td>\n      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0002cc93b.jpg_2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0002cc93b.jpg_3</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['imageid']=df.ImageId_ClassId.apply(lambda x: x.split('_')[0])\ndf['class']=df.ImageId_ClassId.apply(lambda x: x.split('_')[1])","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(3)","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"   ImageId_ClassId                                      EncodedPixels  \\\n0  0002cc93b.jpg_1  29102 12 29346 24 29602 24 29858 24 30114 24 3...   \n1  0002cc93b.jpg_2                                                  0   \n2  0002cc93b.jpg_3                                                  0   \n\n         imageid class  \n0  0002cc93b.jpg     1  \n1  0002cc93b.jpg     2  \n2  0002cc93b.jpg     3  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId_ClassId</th>\n      <th>EncodedPixels</th>\n      <th>imageid</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0002cc93b.jpg_1</td>\n      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n      <td>0002cc93b.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0002cc93b.jpg_2</td>\n      <td>0</td>\n      <td>0002cc93b.jpg</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0002cc93b.jpg_3</td>\n      <td>0</td>\n      <td>0002cc93b.jpg</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"count=0\nclass_list=[]\nclass_count=[]\nmulti_class=[]\ndummy=[]\nm_class=[]\nclass_1=[]\nclass_2=[]\nclass_3=[]\nclass_4=[]\nno_class=[]\nfor i in range(0,len(df['EncodedPixels']),4):\n    for k in range(0+i,4+i):\n        if(df['EncodedPixels'][k]!=0):\n            count+=1\n            dummy.append(int(df['class'][k]))\n            pass\n        if(k==i+3 and count>=1):\n            multi_class.append(dummy)\n            class_count=class_count+dummy\n            class_list.append(i)\n            A=0\n            B=0\n            C=0\n            D=0\n            for x in dummy:\n                if(x==1):A=1 \n                if(x==2):B=1 \n                if(x==3):C=1 \n                if(x==4):D=1 \n                pass\n            m_class.append([A,B,C,D])\n            if(count==1):\n                class_1.append(i)\n                pass\n            elif(count==2):\n                class_2.append(i)\n                pass\n            elif(count==3):\n                class_3.append(i)\n                pass\n            elif(count==4):\n                class_4.append(i)\n                pass\n            pass\n        elif(k==i+3 and count==0):\n            no_class.append(i)\n            \n    count=0\n    dummy=[]\n    pass\n","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dff=pd.DataFrame({'class_types':['Defect_class','Non_defect_class'],'class_count':[len(class_list),(len(df)/4)-len(class_list)]},index=['Defect_classes','Non_defect_classes'])\ndff.plot.barh(x='class_types',y='class_count',figsize=(9,7)).set_title('Class distrubution')\n\nprint('='*80)\n\nprint(len(class_list)/(len(df)/4),'%  of the Images are Defective are')\nprint(1-(len(class_list)/(len(df)/4)),'%  of the Images are Non-Defective are')\n\nprint('='*80)\n\ndff","execution_count":12,"outputs":[{"output_type":"stream","text":"================================================================================\n0.5303946530872056 %  of the Images are Defective are\n0.46960534691279443 %  of the Images are Non-Defective are\n================================================================================\n","name":"stdout"},{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"                         class_types  class_count\nDefect_classes          Defect_class       6666.0\nNon_defect_classes  Non_defect_class       5902.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class_types</th>\n      <th>class_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Defect_classes</th>\n      <td>Defect_class</td>\n      <td>6666.0</td>\n    </tr>\n    <tr>\n      <th>Non_defect_classes</th>\n      <td>Non_defect_class</td>\n      <td>5902.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 648x504 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pf=pd.DataFrame({'index':['class1_Count','class2_Count','class3_Count','class4_Count'],'class_count':[multi_class.count([1]),multi_class.count([2]),multi_class.count([3]),multi_class.count([4])]},index=['class_1','class_2','class_3','class_4'])\npf.plot.pie(x='index',y='class_count',figsize=(9,7)).set_title('Class count distrubution')\nprint('-'*80)\nprint('Majority class is Class_3 with',pf['class_count'].max(),'Data points')\nprint('Minority class is Class_2 with',pf['class_count'].min(),'Data points')\n\nprint('='*80)\nprint('='*80)\npf\n","execution_count":13,"outputs":[{"output_type":"stream","text":"--------------------------------------------------------------------------------\nMajority class is Class_3 with 4759 Data points\nMinority class is Class_2 with 195 Data points\n================================================================================\n================================================================================\n","name":"stdout"},{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"                index  class_count\nclass_1  class1_Count          769\nclass_2  class2_Count          195\nclass_3  class3_Count         4759\nclass_4  class4_Count          516","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>class_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>class_1</th>\n      <td>class1_Count</td>\n      <td>769</td>\n    </tr>\n    <tr>\n      <th>class_2</th>\n      <td>class2_Count</td>\n      <td>195</td>\n    </tr>\n    <tr>\n      <th>class_3</th>\n      <td>class3_Count</td>\n      <td>4759</td>\n    </tr>\n    <tr>\n      <th>class_4</th>\n      <td>class4_Count</td>\n      <td>516</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 648x504 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from prettytable import PrettyTable\ntable=PrettyTable()\ntable.field_names =[\"Type\", \"No.of.classes\",\"Class Id's\",\"Class Data\",'Total_Data','~% of Data']\ntable.add_row(['one class',4,[[1],[2],[3],[4]],list(pf['class_count'].values),len(class_1),float(str(len(class_1)*100/(len(df)/4))[:6]) ])\nt=(multi_class.count([1,2])+multi_class.count([1,3])+multi_class.count([2,3])+multi_class.count([2,4])+multi_class.count([3,4]))\ntable.add_row(['two class',5,[[1,2],[1,3],[2,3],[2,4],[3,4]],[multi_class.count([1,2]),multi_class.count([1,3]),multi_class.count([2,3]),multi_class.count([2,4]),multi_class.count([3,4])],t,float(str((t*100/(len(df)/4)))[:6])])\ntable.add_row(['Three class',1,[[1,2,3]],len(class_3), len(class_3),float(str(len(class_3)*100/(len(df)/4))[:6])])\ntable.add_row(['four class',0,np.nan,np.nan, len(class_4),float(str(len(class_4)*100/(len(df)/4))[:6])])\nprint(table)","execution_count":14,"outputs":[{"output_type":"stream","text":"+-------------+---------------+------------------------------------------+-----------------------+------------+------------+\n|     Type    | No.of.classes |                Class Id's                |       Class Data      | Total_Data | ~% of Data |\n+-------------+---------------+------------------------------------------+-----------------------+------------+------------+\n|  one class  |       4       |           [[1], [2], [3], [4]]           | [769, 195, 4759, 516] |    6239    |   49.641   |\n|  two class  |       5       | [[1, 2], [1, 3], [2, 3], [2, 4], [3, 4]] |  [35, 91, 14, 1, 284] |    425     |   3.3816   |\n| Three class |       1       |               [[1, 2, 3]]                |           2           |     2      |   0.0159   |\n|  four class |       0       |                   nan                    |          nan          |     0      |    0.0     |\n+-------------+---------------+------------------------------------------+-----------------------+------------+------------+\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"id0=df.iloc[no_class, [2]]\nid1=df.iloc[class_list,[2]]\nid0['binary_class']=[0]*len(id0)\n\nid1['binary_class']=[1]*len(id1)\ndf_binary=sklearn.utils.shuffle(pd.concat([id0,id1], axis=0))\ndf_binary['binary_class']=df_binary['binary_class'].astype(str)\nprint(df_binary.shape)\ndf_binary.head()","execution_count":15,"outputs":[{"output_type":"stream","text":"(12568, 2)\n","name":"stdout"},{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"             imageid binary_class\n42216  d62c3879c.jpg            1\n11780  3b08fb5ce.jpg            0\n33856  ac0682b30.jpg            1\n27164  8a09333c4.jpg            1\n8296   29b8c3350.jpg            0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>imageid</th>\n      <th>binary_class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>42216</th>\n      <td>d62c3879c.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11780</th>\n      <td>3b08fb5ce.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>33856</th>\n      <td>ac0682b30.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>27164</th>\n      <td>8a09333c4.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8296</th>\n      <td>29b8c3350.jpg</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df0=df.iloc[no_class, [2]]\ndf0['class1']=[0]*len(id0)\ndf0['class2']=[0]*len(id0)\ndf0['class3']=[0]*len(id0)\ndf0['class4']=[0]*len(id0)\ndf0['any_class']=['0']*len(id0)\nprint(df0.shape)\ndf0.head()","execution_count":16,"outputs":[{"output_type":"stream","text":"(5902, 6)\n","name":"stdout"},{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"          imageid  class1  class2  class3  class4 any_class\n4   00031f466.jpg       0       0       0       0         0\n8   000418bfc.jpg       0       0       0       0         0\n12  000789191.jpg       0       0       0       0         0\n32  001982b08.jpg       0       0       0       0         0\n36  001d1b355.jpg       0       0       0       0         0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>imageid</th>\n      <th>class1</th>\n      <th>class2</th>\n      <th>class3</th>\n      <th>class4</th>\n      <th>any_class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>00031f466.jpg</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>000418bfc.jpg</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>000789191.jpg</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>001982b08.jpg</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>001d1b355.jpg</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"mid=df.iloc[class_list,[2]]\ncolumns =['class1','class2','class3','class4']\nmulc=pd.DataFrame(m_class,columns =columns,index=mid.index)\nmulc['any_class']=[1]*len(mulc)\nmulc=pd.concat([mid,mulc], axis=1)\nmc=pd.concat([mulc,df0], axis=0)\nprint(mc.shape)\nmc.head()","execution_count":17,"outputs":[{"output_type":"stream","text":"(12568, 6)\n","name":"stdout"},{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"          imageid  class1  class2  class3  class4 any_class\n0   0002cc93b.jpg       1       0       0       0         1\n16  0007a71bf.jpg       0       0       1       0         1\n20  000a4bcdd.jpg       1       0       0       0         1\n24  000f6bf48.jpg       0       0       0       1         1\n28  0014fce06.jpg       0       0       1       0         1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>imageid</th>\n      <th>class1</th>\n      <th>class2</th>\n      <th>class3</th>\n      <th>class4</th>\n      <th>any_class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0002cc93b.jpg</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0007a71bf.jpg</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>000a4bcdd.jpg</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>000f6bf48.jpg</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0014fce06.jpg</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"mc['class12']=mc['class1']+mc['class2']+mc['any_class'].astype(int)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bc=mc[mc['class12']!=1]","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Datagen"},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n                 base_path='../input/severstal-steel-defect-detection/train_images',\n                 batch_size=16, dim=(128, 800),preprocess=None, n_channels=3,\n                 n_classes=1, random_state=2019, shuffle=False):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.df = df\n        self.mode = mode\n        self.preprocess = preprocess\n        self.base_path = base_path\n        self.target_df = target_df\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.random_state = random_state\n        self.on_epoch_end()\n    \n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        #print(indexes)\n        # Find list of IDs\n        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n        \n        X = self.__generate_X(list_IDs_batch)\n        \n            \n        if self.mode == 'fit':\n            y = self.__generate_y(list_IDs_batch)\n            return X, y\n        \n        elif self.mode == 'predict':\n            return X\n\n        else:\n            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n        \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.seed(self.random_state)\n            np.random.shuffle(self.indexes)\n    \n    def __generate_X(self, list_IDs_batch):\n        'Generates data containing batch_size samples'\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        \n        # Generate data\n        for i, ID in enumerate(list_IDs_batch):\n            #print(i,ID)\n            im_name = self.df['imageid'][ID]\n            img_path = f\"{self.base_path}/{im_name}\"\n            img = self.__load_rgb(img_path)\n            #print(im_name,img_path)\n            # Store samples\n            img = cv2.resize(img,(self.dim[1],self.dim[0]))\n            X[i,] = img \n            #print(\" X sahpe\",X.shape)\n            #print(\" img sahpe\",img.shape)\n            # normalize \n            #X = X / 255\n        if self.preprocess!=None: X = self.preprocess(X)\n\n        return X\n    \n    def __generate_y(self, list_IDs_batch):\n        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n        \n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['imageid'][ID]\n            #image_df = self.target_df[self.target_df['imageid'] == im_name]\n            \n            rles = self.df['EncodedPixels'][ID]\n            h,w=self.dim\n            masks = rle_to_mask(rles, 256,1600)\n            masks = cv2.resize(masks,(self.dim[1],self.dim[0]))\n\n            #print(\" y sahpe\",y.shape)\n            #print(\" masks sahpe\",masks.shape)\n            y[i, ] = np.expand_dims(masks, -1)\n            y = (y > 0).astype(int)\n        return y \n\n        \n    \n    def __load_rgb(self, img_path):\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = img.astype(np.float32) / 255.\n\n        return img\n    \n    def __load_grayscale(self, img_path):\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = img.astype(np.float32) / 255.\n        img = np.expand_dims(img, axis=-1)\n\n        return img","execution_count":20,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Binary Missing"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\n#https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n#Recall shall be the model metric we use to select our best model when there is a high cost associated with False Negative.\n#TPR\ndef recall(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives / (possible_positives + K.epsilon())\n        return recall","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def precision(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binary = InceptionResNetV2(weights=None, input_shape=(299,299,3), include_top=False)\nbinary.load_weights('/kaggle/input/inceptionresnetv2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5')\nbinary.trainable=False\n\nx=binary.output\nx=GlobalAveragePooling2D()(x)\nx=Dense(128,activation='relu')(x)\nx=Dense(64,activation='relu')(x) \nout=Dense(1,activation='sigmoid')(x) #final layer \n\nclf=Model(inputs=binary.input,outputs=out)","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"for i,layer in enumerate(clf.layers):\n    print(i,layer.name)\n    pass\"\"\"","execution_count":43,"outputs":[{"output_type":"execute_result","execution_count":43,"data":{"text/plain":"'for i,layer in enumerate(clf.layers):\\n    print(i,layer.name)\\n    pass'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy',recall])\n#clf.summary()","execution_count":44,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#ref:https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c\ncolumns =['any_class']\n\nmtr_df, mval_df = train_test_split( bc[0:3000], random_state=42, test_size=0.185)\nprint('train_data shape:',mtr_df.shape,'val_data:',mval_df.shape)\n\ndatagen=ImageDataGenerator(rescale=1./255.,\n                           brightness_range=[0.7,1.0],\n                           rotation_range=50,\n                           horizontal_flip=True,\n                           vertical_flip=True\n                           )\n#test_datagen=ImageDataGenerator(rescale=1./255.)\n\ntrain_gen=datagen.flow_from_dataframe(\ndataframe=mtr_df,\ndirectory=dir1+\"./train_images\",\nx_col=\"imageid\",\ny_col=columns,\nbatch_size=16,\nseed=42,\nshuffle=False,\nclass_mode=\"other\",\ntarget_size=(299,299))\n\nval_gen=datagen.flow_from_dataframe(\ndataframe=mval_df,\ndirectory=dir1+\"./train_images\",\nx_col=\"imageid\",\ny_col=columns,\nbatch_size=16,\nseed=42,\nshuffle=False,\nclass_mode=\"other\",\ntarget_size=(299,299))\n","execution_count":47,"outputs":[{"output_type":"stream","text":"train_data shape: (2445, 7) val_data: (555, 7)\nFound 2445 validated image filenames.\nFound 555 validated image filenames.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEP_SIZE_TRAIN=train_gen.n//train_gen.batch_size\nSTEP_SIZE_VALID=val_gen.n//val_gen.batch_size\n\nhistory1 = clf.fit_generator(train_gen,\n                              steps_per_epoch=STEP_SIZE_TRAIN,\n                              validation_data = val_gen,\n                              validation_steps=STEP_SIZE_VALID,\n                              epochs = 10, verbose=1)","execution_count":48,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n152/152 [==============================] - 178s 1s/step - loss: 0.4994 - acc: 0.7241 - recall: 0.6975 - val_loss: 0.5234 - val_acc: 0.7077 - val_recall: 0.5022\nEpoch 2/10\n152/152 [==============================] - 121s 797ms/step - loss: 0.4149 - acc: 0.8044 - recall: 0.8165 - val_loss: 0.5576 - val_acc: 0.7087 - val_recall: 0.4689\nEpoch 3/10\n152/152 [==============================] - 120s 788ms/step - loss: 0.3637 - acc: 0.8379 - recall: 0.8314 - val_loss: 0.4361 - val_acc: 0.7440 - val_recall: 0.5202\nEpoch 4/10\n 16/152 [==>...........................] - ETA: 1:12 - loss: 0.3805 - acc: 0.8459 - recall: 0.7666","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-e5151b0bcea0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                               \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEP_SIZE_VALID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                               epochs = 10, verbose=1)\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#ref:https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c\ncolumns =['any_class']\n\nmtr_df, mval_df = train_test_split( mc, random_state=42, test_size=0.185)\nprint('train_data shape:',mtr_df.shape,'val_data:',mval_df.shape)\n\ndatagen=ImageDataGenerator(rescale=1./255.,\n                           brightness_range=[0.7,1.0],\n                           rotation_range=50,\n                           horizontal_flip=True,\n                           vertical_flip=True\n                           )\n#test_datagen=ImageDataGenerator(rescale=1./255.)\n\ntrain_gen=datagen.flow_from_dataframe(\ndataframe=mtr_df,\ndirectory=dir1+\"./train_images\",\nx_col=\"imageid\",\ny_col=columns,\nbatch_size=16,\nseed=42,\nshuffle=False,\nclass_mode=\"other\",\ntarget_size=(299,299))\n\nval_gen=datagen.flow_from_dataframe(\ndataframe=mval_df,\ndirectory=dir1+\"./train_images\",\nx_col=\"imageid\",\ny_col=columns,\nbatch_size=16,\nseed=42,\nshuffle=False,\nclass_mode=\"other\",\ntarget_size=(299,299))\n","execution_count":49,"outputs":[{"output_type":"stream","text":"train_data shape: (10242, 7) val_data: (2326, 7)\nFound 10242 validated image filenames.\nFound 2326 validated image filenames.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEP_SIZE_TRAIN=train_gen.n//train_gen.batch_size\nSTEP_SIZE_VALID=val_gen.n//val_gen.batch_size\n\nhistory1 = clf.fit_generator(train_gen,\n                              steps_per_epoch=STEP_SIZE_TRAIN,\n                              validation_data = val_gen,\n                              validation_steps=STEP_SIZE_VALID,\n                              epochs = 25, verbose=1)","execution_count":50,"outputs":[{"output_type":"stream","text":"Epoch 1/25\n149/640 [=====>........................] - ETA: 6:02 - loss: 0.5242 - acc: 0.7496 - recall: 0.7850","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-50-7b9d6c8268cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                               \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEP_SIZE_VALID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                               epochs = 25, verbose=1)\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.save_weights(\"Binary_more_wc12.h5\")\nprint(\"Saved model to disk\")","execution_count":51,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-51-ed7ce9424fed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Binary_more_wc12.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saved model to disk\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(self, filepath, overwrite)\u001b[0m\n\u001b[1;32m   1119\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m             \u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights_to_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_weights_to_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0msymbolic_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mweight_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m         \u001b[0mweight_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[0;34m(ops)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \"\"\"\n\u001b[1;32m   2419\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{},"cell_type":"markdown","source":"## Multi label Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#ref:https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c\ncolumns =['class1','class2','class3','class4']\n\nmtr_df, mval_df = train_test_split( mc, random_state=42, test_size=0.225)\nprint('train_data shape:',mtr_df.shape,'val_data:',mval_df.shape)\n\ndatagen=ImageDataGenerator(rescale=1./255.,\n                           shear_range=0.1,\n                           zoom_range=0.1,\n                           brightness_range=[0.6,1.0],\n                           rotation_range=60,\n                           horizontal_flip=True,\n                           vertical_flip=True\n                           )\n#test_datagen=ImageDataGenerator(rescale=1./255.)\n\ntrain_gen=datagen.flow_from_dataframe(\ndataframe=mtr_df,\ndirectory=dir1+\"./train_images\",\nx_col=\"imageid\",\ny_col=columns,\nbatch_size=16,\nseed=42,\nshuffle=False,\nclass_mode=\"other\",\ntarget_size=(299,299))\n\nval_gen=datagen.flow_from_dataframe(\ndataframe=mval_df,\ndirectory=dir1+\"./train_images\",\nx_col=\"imageid\",\ny_col=columns,\nbatch_size=16,\nseed=42,\nshuffle=False,\nclass_mode=\"other\",\ntarget_size=(299,299))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = InceptionResNetV2(weights=None, input_shape=(299,299,3), include_top=False)\nmodel.load_weights('/kaggle/input/inceptionresnetv2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5')\nmodel.trainable=False\n\nx=model.output\nx=GlobalAveragePooling2D()(x)\nx=Dense(128,activation='relu')(x)\nx=Dense(64,activation='relu')(x) \nout=Dense(4,activation='sigmoid')(x) #final layer 5 clases\n\nmodel_m=Model(inputs=model.input,outputs=out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,layer in enumerate(model_m.layers):\n    print(i,layer.name)\n    pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"for layer in model_m.layers:\n    layer.trainable=False\n# or if we want to set the first 19 layers of the network to be non-trainable\nfor layer in model_m.layers[:780]:\n    layer.trainable=False\nfor layer in model_m.layers[780:]:\n    layer.trainable=True \"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_m.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy',precision,recall])\nmodel_m.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEP_SIZE_TRAIN=train_gen.n//train_gen.batch_size\nSTEP_SIZE_VALID=val_gen.n//val_gen.batch_size\n\nhistory = model_m.fit_generator(train_gen,\n                              steps_per_epoch=STEP_SIZE_TRAIN,\n                              validation_data = val_gen,\n                              validation_steps=STEP_SIZE_VALID,\n                              epochs = 35, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"model_m.evaluate_generator(val_gen,\n                              steps=STEP_SIZE_VALID,\n                               verbose=1)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_m.save(\"multic_aug.h5\")\nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"from IPython.display import FileLink\nFileLink(r'multic_aug.h5')\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from keras.models import load_model\n# load model\n#model2 = load_model('model_multic.h5', custom_objects={\"precision\": precision,\"recall\":recall})\n# summarize model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"for i in range(len(sub0)):\n    if(binary_preds[i]>= 0.3):\n        sub0['class'][i*4]=1\n        pass\n    else:\n        sub0['class'][i*4]=0\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"print(\"class count\",sub0['class'].value_counts())\nprint(\"shape:\",sub0.shape)\nsub0.tail()\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"sub_mul=sub0[sub0['class']==1]\nprint(sub_mul.shape)\nsub_mul.head()\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ##  mask pred"},{"metadata":{},"cell_type":"markdown","source":"### Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#This dataframe is for prediction\nnf=df[['imageid','EncodedPixels','class']][df['EncodedPixels']!=0]\nnf['class1']=nf['class'].apply(lambda c:1 if int(c)==1 else 0)\nnf['class2']=nf['class'].apply(lambda c:1 if int(c)==2 else 0)\nnf['class3']=nf['class'].apply(lambda c:1 if int(c)==3 else 0)\nnf['class4']=nf['class'].apply(lambda c:1 if int(c)==4 else 0)\nprint(\"shape of dataframe:\",nf.shape)\nnf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c1=nf[nf['class1']!=0]\nc2=nf[nf['class2']!=0]\nc3=nf[nf['class3']!=0]\nc4=nf[nf['class4']!=0]\nprint(\"Class1 data shape\",c1.shape)\nprint(\"Class2 data shape\",c2.shape)\nprint(\"Class3 data shape\",c3.shape)\nprint(\"Class4 data shape\",c4.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install segmentation-models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from segmentation_models import Unet\nfrom segmentation_models.backbones import get_preprocessing\n#model = Unet('resnet34')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LOAD UNET WITH PRETRAINING FROM IMAGENET\npreprocess = get_preprocessing('resnet34') # for resnet, img = (img-110.0)/1.0\nmodel = Unet('resnet34', input_shape=(128, 800, 3), classes=1, activation='sigmoid')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,layer in enumerate(model.layers):\n    print(i,layer.name)\n    pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rle_to_mask(rle_string, height, width):\n    \n    rows, cols = height, width\n    img = np.zeros(rows * cols, dtype=np.uint8)\n    if len(str(rle_string)) > 1:\n        rle_numbers = [int(numstring) for numstring in rle_string.split(' ')]\n        rle_pairs = np.array(rle_numbers).reshape(-1, 2)\n        for index, length in rle_pairs:\n            index -= 1\n            img[index:index+length] = 255\n    else: img = np.zeros(cols*rows)\n    img = img.reshape(cols, rows)\n    img = img.T\n    return img\n\n\ndef mask_to_rle(mask):\n    '''\n    Convert a mask into RLE\n    \n    Parameters: \n    mask (numpy.array): binary mask of numpy array where 1 - mask, 0 - background\n\n    Returns: \n    sring: run length encoding \n    '''\n    pixels= mask.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'metric and loss function for evaluation'\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2 * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef loss_dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return -K.log((2 * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load(BATCH_SIZE,index_df,dff,dimn):\n    \n    train_idx, val_idx = train_test_split(\n    index_df.index,  # Index matters for each prediction class\n    random_state=2019, \n    test_size=0.15)\n\n    train_generator = DataGenerator(\n        train_idx, \n        df=dff,\n        dim=dimn,\n        batch_size=BATCH_SIZE, \n        n_classes=1)\n\n    val_generator = DataGenerator(\n        val_idx, \n        df=nf,\n        dim=dimn,\n        batch_size=BATCH_SIZE, \n        n_classes=1)\n    \n    \n    return train_generator,val_generator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load data\ntrainc1,valc1=load(8,c1,nf,dimn=(128,800))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_c1 = Unet('resnet34', input_shape=(128, 800, 3), classes=1, activation='sigmoid')\npred_c1.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef,loss_dice_coef])\npred_c1.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fit data gen\nhistory = pred_c1.fit_generator(\n    trainc1,\n    validation_data=valc1,\n    use_multiprocessing=False,\n    workers=1,\n    epochs=30 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.save(\"pred_c1.h5\")\nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Class2"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load data\ntrainc2,valc2=load(8,c2,nf,dimn=(128,800))\npred_c2 = Unet('resnet34', input_shape=(128, 800, 3), classes=1, activation='sigmoid')\npred_c2.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef,loss_dice_coef])\npred_c2.summary()\n#fit data gen\nhistory2 = pred_c2.fit_generator(\n    trainc2,\n    validation_data=valc2,\n    use_multiprocessing=False,\n    workers=1,\n    epochs=35 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fit data gen\nhistory2 = pred_c2.fit_generator(\n    trainc2,\n    validation_data=valc2,\n    use_multiprocessing=False,\n    workers=1,\n    epochs=35)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.save(\"pred_c2.h5\")\nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Class3"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load data\ntrainc3,valc3=load(8,c3,nf,dimn=(128,800))\npred_c3 = Unet('resnet34', input_shape=(128, 800, 3), classes=1, activation='sigmoid')\npred_c3.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef,loss_dice_coef])\npred_c3.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fit data gen\nhistory3 = pred_c3.fit_generator(\n    trainc3,\n    validation_data=valc3,\n    use_multiprocessing=False,\n    workers=1,\n    epochs=35 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.save(\"pred_c3.h5\")\nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Class4"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load data\ntrainc4,valc4=load(8,c4,nf,dimn=(128,800))\npred_c4 = Unet('resnet34', input_shape=(128, 800, 3), classes=1, activation='sigmoid')\npred_c4.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef,loss_dice_coef])\npred_c4.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fit data gen\nhistory4 = pred_c4.fit_generator(\n    trainc4,\n    validation_data=valc4,\n    use_multiprocessing=False,\n    workers=1,\n    epochs=30 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.save(\"pred_c4.h5\")\nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":1}