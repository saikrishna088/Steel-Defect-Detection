{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sklearn\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization,Input\nfrom keras.layers import Conv1D, Conv2D, MaxPooling2D,Conv2DTranspose,UpSampling2D\nfrom keras import regularizers, optimizers,Sequential\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport cv2\nimport keras\nfrom sklearn.metrics import recall_score\nfrom tensorflow.python.keras import backend as K \nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm_notebook\nimport os\n\n\nfrom keras.layers import Dense,GlobalAveragePooling2D\nfrom keras.applications import MobileNet\nfrom keras.preprocessing import image\nfrom keras.applications.mobilenet import preprocess_input\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        #print(os.path.join(dirname, filename))\n#        print(dirname)\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('/kaggle/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('/kaggle/input')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('/kaggle/input/severstal-steel-defect-detection')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('/kaggle/input/severstal-steel-defect-detection/')\ndir1='/kaggle/input/severstal-steel-defect-detection/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(dir1+'train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub=pd.read_csv(dir1+'sample_submission.csv')\nsub['imageid']=sub.ImageId_ClassId.apply(lambda x: x.split('_')[0])\nsub['class']=sub.ImageId_ClassId.apply(lambda x: int(x.split('_')[1]))\nprint(sub.shape)\nsub.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.fillna(0,inplace=True)\ndf.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['imageid']=df.ImageId_ClassId.apply(lambda x: x.split('_')[0])\ndf['class']=df.ImageId_ClassId.apply(lambda x: x.split('_')[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count=0\nclass_list=[]\nclass_count=[]\nmulti_class=[]\ndummy=[]\nm_class=[]\nclass_1=[]\nclass_2=[]\nclass_3=[]\nclass_4=[]\nno_class=[]\nfor i in range(0,len(df['EncodedPixels']),4):\n    for k in range(0+i,4+i):\n        if(df['EncodedPixels'][k]!=0):\n            count+=1\n            dummy.append(int(df['class'][k]))\n            pass\n        if(k==i+3 and count>=1):\n            multi_class.append(dummy)\n            class_count=class_count+dummy\n            class_list.append(i)\n            A=0\n            B=0\n            C=0\n            D=0\n            for x in dummy:\n                if(x==1):A=1 \n                if(x==2):B=1 \n                if(x==3):C=1 \n                if(x==4):D=1 \n                pass\n            m_class.append([A,B,C,D])\n            if(count==1):\n                class_1.append(i)\n                pass\n            elif(count==2):\n                class_2.append(i)\n                pass\n            elif(count==3):\n                class_3.append(i)\n                pass\n            elif(count==4):\n                class_4.append(i)\n                pass\n            pass\n        elif(k==i+3 and count==0):\n            no_class.append(i)\n            \n    count=0\n    dummy=[]\n    pass\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dff=pd.DataFrame({'class_types':['Defect_class','Non_defect_class'],'class_count':[len(class_list),(len(df)/4)-len(class_list)]},index=['Defect_classes','Non_defect_classes'])\ndff.plot.barh(x='class_types',y='class_count',figsize=(9,7)).set_title('Class distrubution')\n\nprint('='*80)\n\nprint(len(class_list)/(len(df)/4),'%  of the Images are Defective are')\nprint(1-(len(class_list)/(len(df)/4)),'%  of the Images are Non-Defective are')\n\nprint('='*80)\n\ndff","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pf=pd.DataFrame({'index':['class1_Count','class2_Count','class3_Count','class4_Count'],'class_count':[multi_class.count([1]),multi_class.count([2]),multi_class.count([3]),multi_class.count([4])]},index=['class_1','class_2','class_3','class_4'])\npf.plot.pie(x='index',y='class_count',figsize=(9,7)).set_title('Class count distrubution')\nprint('-'*80)\nprint('Majority class is Class_3 with',pf['class_count'].max(),'Data points')\nprint('Minority class is Class_2 with',pf['class_count'].min(),'Data points')\n\nprint('='*80)\nprint('='*80)\npf\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from prettytable import PrettyTable\ntable=PrettyTable()\ntable.field_names =[\"Type\", \"No.of.classes\",\"Class Id's\",\"Class Data\",'Total_Data','~% of Data']\ntable.add_row(['one class',4,[[1],[2],[3],[4]],list(pf['class_count'].values),len(class_1),float(str(len(class_1)*100/(len(df)/4))[:6]) ])\nt=(multi_class.count([1,2])+multi_class.count([1,3])+multi_class.count([2,3])+multi_class.count([2,4])+multi_class.count([3,4]))\ntable.add_row(['two class',5,[[1,2],[1,3],[2,3],[2,4],[3,4]],[multi_class.count([1,2]),multi_class.count([1,3]),multi_class.count([2,3]),multi_class.count([2,4]),multi_class.count([3,4])],t,float(str((t*100/(len(df)/4)))[:6])])\ntable.add_row(['Three class',1,[[1,2,3]],len(class_3), len(class_3),float(str(len(class_3)*100/(len(df)/4))[:6])])\ntable.add_row(['four class',0,np.nan,np.nan, len(class_4),float(str(len(class_4)*100/(len(df)/4))[:6])])\nprint(table)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"id0=df.iloc[no_class, [2]]\nid1=df.iloc[class_list,[2]]\nid0['binary_class']=[0]*len(id0)\n\nid1['binary_class']=[1]*len(id1)\ndf_binary=sklearn.utils.shuffle(pd.concat([id0,id1], axis=0))\ndf_binary['binary_class']=df_binary['binary_class'].astype(str)\nprint(df_binary.shape)\ndf_binary.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df0=df.iloc[no_class, [2]]\ndf0['class1']=[0]*len(id0)\ndf0['class2']=[0]*len(id0)\ndf0['class3']=[0]*len(id0)\ndf0['class4']=[0]*len(id0)\ndf0['any_class']=['0']*len(id0)\nprint(df0.shape)\ndf0.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mid=df.iloc[class_list,[2]]\ncolumns =['class1','class2','class3','class4']\nmulc=pd.DataFrame(m_class,columns =columns,index=mid.index)\nmulc['any_class']=[1]*len(mulc)\nmulc=pd.concat([mid,mulc], axis=1)\nmc=pd.concat([mulc,df0], axis=0)\nprint(mc.shape)\nmc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mc['any_class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Datagen"},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n                 base_path='../input/severstal-steel-defect-detection/train_images',\n                 batch_size=16, dim=(128, 800),preprocess=None, n_channels=3,\n                 n_classes=1, random_state=2019, shuffle=False):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.df = df\n        self.mode = mode\n        self.preprocess = preprocess\n        self.base_path = base_path\n        self.target_df = target_df\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.random_state = random_state\n        self.on_epoch_end()\n    \n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        #print(indexes)\n        # Find list of IDs\n        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n        \n        X = self.__generate_X(list_IDs_batch)\n        \n            \n        if self.mode == 'fit':\n            y = self.__generate_y(list_IDs_batch)\n            return X, y\n        \n        elif self.mode == 'predict':\n            return X\n\n        else:\n            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n        \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.seed(self.random_state)\n            np.random.shuffle(self.indexes)\n    \n    def __generate_X(self, list_IDs_batch):\n        'Generates data containing batch_size samples'\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        \n        # Generate data\n        for i, ID in enumerate(list_IDs_batch):\n            #print(i,ID)\n            im_name = self.df['imageid'][ID]\n            img_path = f\"{self.base_path}/{im_name}\"\n            img = self.__load_rgb(img_path)\n            #print(im_name,img_path)\n            # Store samples\n            img = cv2.resize(img,(800,128))\n            X[i,] = img \n            #print(\" X sahpe\",X.shape)\n            #print(\" img sahpe\",img.shape)\n            # normalize \n            #X = X / 255\n        if self.preprocess!=None: X = self.preprocess(X)\n\n        return X\n    \n    def __generate_y(self, list_IDs_batch):\n        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n        \n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['imageid'][ID]\n            #image_df = self.target_df[self.target_df['imageid'] == im_name]\n            \n            rles = self.df['EncodedPixels'][ID]\n            h,w=self.dim\n            masks = rle_to_mask(rles, 256,1600)\n            masks = cv2.resize(masks,(800,128))\n\n            #print(\" y sahpe\",y.shape)\n            #print(\" masks sahpe\",masks.shape)\n            y[i, ] = np.expand_dims(masks, -1)\n            y = (y > 0).astype(int)\n        return y \n\n        \n    \n    def __load_rgb(self, img_path):\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = img.astype(np.float32) / 255.\n\n        return img\n    \n    def __load_grayscale(self, img_path):\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = img.astype(np.float32) / 255.\n        img = np.expand_dims(img, axis=-1)\n\n        return img","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Binary Missing"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\n#https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n#Recall shall be the model metric we use to select our best model when there is a high cost associated with False Negative.\n#TPR\ndef recall(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives / (possible_positives + K.epsilon())\n        return recall","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def precision(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binary = InceptionResNetV2(weights=None, input_shape=(299,299,3), include_top=False)\nbinary.load_weights('/kaggle/input/inceptionresnetv2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5')\nbinary.trainable=False\n\nx=binary.output\nx=GlobalAveragePooling2D()(x)\nx=Dense(128,activation='relu')(x)\nx=Dense(64,activation='relu')(x) \nout=Dense(1,activation='sigmoid')(x) #final layer \n\nclf=Model(inputs=binary.input,outputs=out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,layer in enumerate(clf.layers):\n    print(i,layer.name)\n    pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy',recall])\nclf.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEP_SIZE_TRAIN=train_gen.n//train_gen.batch_size\nSTEP_SIZE_VALID=val_gen.n//val_gen.batch_size\n\nhistory1 = clf.fit_generator(train_gen,\n                              steps_per_epoch=STEP_SIZE_TRAIN,\n                              validation_data = val_gen,\n                              validation_steps=STEP_SIZE_VALID,\n                              epochs = 35, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.save(\"Binary_aug.h5\")\nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Multi label Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#ref:https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c\ncolumns =['class1','class2','class3','class4']\n\nmtr_df, mval_df = train_test_split( mc, random_state=42, test_size=0.225)\nprint('train_data shape:',mtr_df.shape,'val_data:',mval_df.shape)\n\ndatagen=ImageDataGenerator(rescale=1./255.,\n                           shear_range=0.1,\n                           zoom_range=0.1,\n                           brightness_range=[0.6,1.0],\n                           rotation_range=60,\n                           horizontal_flip=True,\n                           vertical_flip=True\n                           )\n#test_datagen=ImageDataGenerator(rescale=1./255.)\n\ntrain_gen=datagen.flow_from_dataframe(\ndataframe=mtr_df,\ndirectory=dir1+\"./train_images\",\nx_col=\"imageid\",\ny_col=columns,\nbatch_size=16,\nseed=42,\nshuffle=False,\nclass_mode=\"other\",\ntarget_size=(299,299))\n\nval_gen=datagen.flow_from_dataframe(\ndataframe=mval_df,\ndirectory=dir1+\"./train_images\",\nx_col=\"imageid\",\ny_col=columns,\nbatch_size=16,\nseed=42,\nshuffle=False,\nclass_mode=\"other\",\ntarget_size=(299,299))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = InceptionResNetV2(weights=None, input_shape=(299,299,3), include_top=False)\nmodel.load_weights('/kaggle/input/inceptionresnetv2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5')\nmodel.trainable=False\n\nx=model.output\nx=GlobalAveragePooling2D()(x)\nx=Dense(128,activation='relu')(x)\nx=Dense(64,activation='relu')(x) \nout=Dense(4,activation='sigmoid')(x) #final layer 5 clases\n\nmodel_m=Model(inputs=model.input,outputs=out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,layer in enumerate(model_m.layers):\n    print(i,layer.name)\n    pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"for layer in model_m.layers:\n    layer.trainable=False\n# or if we want to set the first 19 layers of the network to be non-trainable\nfor layer in model_m.layers[:780]:\n    layer.trainable=False\nfor layer in model_m.layers[780:]:\n    layer.trainable=True \"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_m.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy',precision,recall])\nmodel_m.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEP_SIZE_TRAIN=train_gen.n//train_gen.batch_size\nSTEP_SIZE_VALID=val_gen.n//val_gen.batch_size\n\nhistory = model_m.fit_generator(train_gen,\n                              steps_per_epoch=STEP_SIZE_TRAIN,\n                              validation_data = val_gen,\n                              validation_steps=STEP_SIZE_VALID,\n                              epochs = 35, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"model_m.evaluate_generator(val_gen,\n                              steps=STEP_SIZE_VALID,\n                               verbose=1)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_m.save(\"multic_aug.h5\")\nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"from IPython.display import FileLink\nFileLink(r'multic_aug.h5')\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from keras.models import load_model\n# load model\n#model2 = load_model('model_multic.h5', custom_objects={\"precision\": precision,\"recall\":recall})\n# summarize model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"for i in range(len(sub0)):\n    if(binary_preds[i]>= 0.3):\n        sub0['class'][i*4]=1\n        pass\n    else:\n        sub0['class'][i*4]=0\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"print(\"class count\",sub0['class'].value_counts())\nprint(\"shape:\",sub0.shape)\nsub0.tail()\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"sub_mul=sub0[sub0['class']==1]\nprint(sub_mul.shape)\nsub_mul.head()\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ##  mask pred"},{"metadata":{},"cell_type":"markdown","source":"### Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#This dataframe is for prediction\nnf=df[['imageid','EncodedPixels','class']][df['EncodedPixels']!=0]\nnf['class1']=nf['class'].apply(lambda c:1 if int(c)==1 else 0)\nnf['class2']=nf['class'].apply(lambda c:1 if int(c)==2 else 0)\nnf['class3']=nf['class'].apply(lambda c:1 if int(c)==3 else 0)\nnf['class4']=nf['class'].apply(lambda c:1 if int(c)==4 else 0)\nprint(\"shape of dataframe:\",nf.shape)\nnf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c1=nf[nf['class1']!=0]\nc2=nf[nf['class2']!=0]\nc3=nf[nf['class3']!=0]\nc4=nf[nf['class4']!=0]\nprint(\"Class1 data shape\",c1.shape)\nprint(\"Class2 data shape\",c2.shape)\nprint(\"Class3 data shape\",c3.shape)\nprint(\"Class4 data shape\",c4.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install segmentation-models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from segmentation_models import Unet\nfrom segmentation_models.backbones import get_preprocessing\n#model = Unet('resnet34')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LOAD UNET WITH PRETRAINING FROM IMAGENET\npreprocess = get_preprocessing('resnet34') # for resnet, img = (img-110.0)/1.0\nmodel = Unet('resnet34', input_shape=(128, 800, 3), classes=1, activation='sigmoid')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,layer in enumerate(model.layers):\n    print(i,layer.name)\n    pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rle_to_mask(rle_string, height, width):\n    \n    rows, cols = height, width\n    img = np.zeros(rows * cols, dtype=np.uint8)\n    if len(str(rle_string)) > 1:\n        rle_numbers = [int(numstring) for numstring in rle_string.split(' ')]\n        rle_pairs = np.array(rle_numbers).reshape(-1, 2)\n        for index, length in rle_pairs:\n            index -= 1\n            img[index:index+length] = 255\n    else: img = np.zeros(cols*rows)\n    img = img.reshape(cols, rows)\n    img = img.T\n    return img\n\n\ndef mask_to_rle(mask):\n    '''\n    Convert a mask into RLE\n    \n    Parameters: \n    mask (numpy.array): binary mask of numpy array where 1 - mask, 0 - background\n\n    Returns: \n    sring: run length encoding \n    '''\n    pixels= mask.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'metric and loss function for evaluation'\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2 * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef loss_dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return -K.log((2 * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load(BATCH_SIZE,index_df,dff,dimn):\n    \n    train_idx, val_idx = train_test_split(\n    index_df.index,  # Index matters for each prediction class\n    random_state=2019, \n    test_size=0.15)\n\n    train_generator = DataGenerator(\n        train_idx, \n        df=dff,\n        dim=dimn,\n        batch_size=BATCH_SIZE, \n        n_classes=1)\n\n    val_generator = DataGenerator(\n        val_idx, \n        df=nf,\n        dim=dimn,\n        batch_size=BATCH_SIZE, \n        n_classes=1)\n    \n    \n    return train_generator,val_generator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load data\ntrainc1,valc1=load(8,c1,nf,dimn=(128,800))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_c1 = Unet('resnet34', input_shape=(128, 800, 3), classes=1, activation='sigmoid')\npred_c1.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef,loss_dice_coef])\npred_c1.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fit data gen\nhistory = pred_c1.fit_generator(\n    trainc1,\n    validation_data=valc1,\n    use_multiprocessing=False,\n    workers=1,\n    epochs=30 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.save(\"pred_c1.h5\")\nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Class2"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load data\ntrainc2,valc2=load(8,c2,nf,dimn=(128,800))\npred_c2 = Unet('resnet34', input_shape=(128, 800, 3), classes=1, activation='sigmoid')\npred_c2.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef,loss_dice_coef])\npred_c2.summary()\n#fit data gen\nhistory2 = pred_c2.fit_generator(\n    trainc2,\n    validation_data=valc2,\n    use_multiprocessing=False,\n    workers=1,\n    epochs=35 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fit data gen\nhistory2 = pred_c2.fit_generator(\n    trainc2,\n    validation_data=valc2,\n    use_multiprocessing=False,\n    workers=1,\n    epochs=35)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.save(\"pred_c2.h5\")\nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Class3"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load data\ntrainc3,valc3=load(8,c3,nf,dimn=(128,800))\npred_c3 = Unet('resnet34', input_shape=(128, 800, 3), classes=1, activation='sigmoid')\npred_c3.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef,loss_dice_coef])\npred_c3.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fit data gen\nhistory3 = pred_c3.fit_generator(\n    trainc3,\n    validation_data=valc3,\n    use_multiprocessing=False,\n    workers=1,\n    epochs=35 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.save(\"pred_c3.h5\")\nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Class4"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load data\ntrainc4,valc4=load(8,c4,nf,dimn=(128,800))\npred_c4 = Unet('resnet34', input_shape=(128, 800, 3), classes=1, activation='sigmoid')\npred_c4.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef,loss_dice_coef])\npred_c4.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fit data gen\nhistory4 = pred_c4.fit_generator(\n    trainc4,\n    validation_data=valc4,\n    use_multiprocessing=False,\n    workers=1,\n    epochs=30 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.save(\"pred_c4.h5\")\nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":1}