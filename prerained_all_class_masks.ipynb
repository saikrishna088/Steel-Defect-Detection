{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import sklearn\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization,Input\n",
    "from keras.layers import Conv1D, Conv2D, MaxPooling2D,Conv2DTranspose,UpSampling2D\n",
    "from keras import regularizers, optimizers,Sequential\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import cv2\n",
    "import keras\n",
    "from sklearn.metrics import recall_score\n",
    "from tensorflow.python.keras import backend as K \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm_notebook\n",
    "import os\n",
    "\n",
    "\n",
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "from keras.applications import MobileNet\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#        #print(os.path.join(dirname, filename))\n",
    "#        print(dirname)\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['src', 'lib', 'input', 'working']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/kaggle/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['severstal-steel-defect-detection']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/kaggle/input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submission.csv', 'train.csv', 'train_images', 'test_images']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/kaggle/input/severstal-steel-defect-detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('/kaggle/input/severstal-steel-defect-detection/')\n",
    "dir1='/kaggle/input/severstal-steel-defect-detection/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(dir1+'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7204, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId_ClassId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>imageid</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>004f40c73.jpg_1</td>\n",
       "      <td>1 1</td>\n",
       "      <td>004f40c73.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004f40c73.jpg_2</td>\n",
       "      <td>1 1</td>\n",
       "      <td>004f40c73.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004f40c73.jpg_3</td>\n",
       "      <td>1 1</td>\n",
       "      <td>004f40c73.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004f40c73.jpg_4</td>\n",
       "      <td>1 1</td>\n",
       "      <td>004f40c73.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>006f39c41.jpg_1</td>\n",
       "      <td>1 1</td>\n",
       "      <td>006f39c41.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId_ClassId EncodedPixels        imageid  class\n",
       "0  004f40c73.jpg_1           1 1  004f40c73.jpg      1\n",
       "1  004f40c73.jpg_2           1 1  004f40c73.jpg      2\n",
       "2  004f40c73.jpg_3           1 1  004f40c73.jpg      3\n",
       "3  004f40c73.jpg_4           1 1  004f40c73.jpg      4\n",
       "4  006f39c41.jpg_1           1 1  006f39c41.jpg      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub=pd.read_csv(dir1+'sample_submission.csv')\n",
    "sub['imageid']=sub.ImageId_ClassId.apply(lambda x: x.split('_')[0])\n",
    "sub['class']=sub.ImageId_ClassId.apply(lambda x: int(x.split('_')[1]))\n",
    "print(sub.shape)\n",
    "sub.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId_ClassId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002cc93b.jpg_1</td>\n",
       "      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002cc93b.jpg_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002cc93b.jpg_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId_ClassId                                      EncodedPixels\n",
       "0  0002cc93b.jpg_1  29102 12 29346 24 29602 24 29858 24 30114 24 3...\n",
       "1  0002cc93b.jpg_2                                                  0\n",
       "2  0002cc93b.jpg_3                                                  0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna(0,inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['imageid']=df.ImageId_ClassId.apply(lambda x: x.split('_')[0])\n",
    "df['class']=df.ImageId_ClassId.apply(lambda x: x.split('_')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId_ClassId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>imageid</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002cc93b.jpg_1</td>\n",
       "      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n",
       "      <td>0002cc93b.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002cc93b.jpg_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0002cc93b.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002cc93b.jpg_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0002cc93b.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId_ClassId                                      EncodedPixels  \\\n",
       "0  0002cc93b.jpg_1  29102 12 29346 24 29602 24 29858 24 30114 24 3...   \n",
       "1  0002cc93b.jpg_2                                                  0   \n",
       "2  0002cc93b.jpg_3                                                  0   \n",
       "\n",
       "         imageid class  \n",
       "0  0002cc93b.jpg     1  \n",
       "1  0002cc93b.jpg     2  \n",
       "2  0002cc93b.jpg     3  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "class_list=[]\n",
    "class_count=[]\n",
    "multi_class=[]\n",
    "dummy=[]\n",
    "m_class=[]\n",
    "class_1=[]\n",
    "class_2=[]\n",
    "class_3=[]\n",
    "class_4=[]\n",
    "no_class=[]\n",
    "for i in range(0,len(df['EncodedPixels']),4):\n",
    "    for k in range(0+i,4+i):\n",
    "        if(df['EncodedPixels'][k]!=0):\n",
    "            count+=1\n",
    "            dummy.append(int(df['class'][k]))\n",
    "            pass\n",
    "        if(k==i+3 and count>=1):\n",
    "            multi_class.append(dummy)\n",
    "            class_count=class_count+dummy\n",
    "            class_list.append(i)\n",
    "            A=0\n",
    "            B=0\n",
    "            C=0\n",
    "            D=0\n",
    "            for x in dummy:\n",
    "                if(x==1):A=1 \n",
    "                if(x==2):B=1 \n",
    "                if(x==3):C=1 \n",
    "                if(x==4):D=1 \n",
    "                pass\n",
    "            m_class.append([A,B,C,D])\n",
    "            if(count==1):\n",
    "                class_1.append(i)\n",
    "                pass\n",
    "            elif(count==2):\n",
    "                class_2.append(i)\n",
    "                pass\n",
    "            elif(count==3):\n",
    "                class_3.append(i)\n",
    "                pass\n",
    "            elif(count==4):\n",
    "                class_4.append(i)\n",
    "                pass\n",
    "            pass\n",
    "        elif(k==i+3 and count==0):\n",
    "            no_class.append(i)\n",
    "            \n",
    "    count=0\n",
    "    dummy=[]\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "0.5303946530872056 %  of the Images are Defective are\n",
      "0.46960534691279443 %  of the Images are Non-Defective are\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_types</th>\n",
       "      <th>class_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Defect_classes</th>\n",
       "      <td>Defect_class</td>\n",
       "      <td>6666.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non_defect_classes</th>\n",
       "      <td>Non_defect_class</td>\n",
       "      <td>5902.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         class_types  class_count\n",
       "Defect_classes          Defect_class       6666.0\n",
       "Non_defect_classes  Non_defect_class       5902.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dff=pd.DataFrame({'class_types':['Defect_class','Non_defect_class'],'class_count':[len(class_list),(len(df)/4)-len(class_list)]},index=['Defect_classes','Non_defect_classes'])\n",
    "dff.plot.barh(x='class_types',y='class_count',figsize=(9,7)).set_title('Class distrubution')\n",
    "\n",
    "print('='*80)\n",
    "\n",
    "print(len(class_list)/(len(df)/4),'%  of the Images are Defective are')\n",
    "print(1-(len(class_list)/(len(df)/4)),'%  of the Images are Non-Defective are')\n",
    "\n",
    "print('='*80)\n",
    "\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Majority class is Class_3 with 4759 Data points\n",
      "Minority class is Class_2 with 195 Data points\n",
      "================================================================================\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>class_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class_1</th>\n",
       "      <td>class1_Count</td>\n",
       "      <td>769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_2</th>\n",
       "      <td>class2_Count</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_3</th>\n",
       "      <td>class3_Count</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_4</th>\n",
       "      <td>class4_Count</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                index  class_count\n",
       "class_1  class1_Count          769\n",
       "class_2  class2_Count          195\n",
       "class_3  class3_Count         4759\n",
       "class_4  class4_Count          516"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pf=pd.DataFrame({'index':['class1_Count','class2_Count','class3_Count','class4_Count'],'class_count':[multi_class.count([1]),multi_class.count([2]),multi_class.count([3]),multi_class.count([4])]},index=['class_1','class_2','class_3','class_4'])\n",
    "pf.plot.pie(x='index',y='class_count',figsize=(9,7)).set_title('Class count distrubution')\n",
    "print('-'*80)\n",
    "print('Majority class is Class_3 with',pf['class_count'].max(),'Data points')\n",
    "print('Minority class is Class_2 with',pf['class_count'].min(),'Data points')\n",
    "\n",
    "print('='*80)\n",
    "print('='*80)\n",
    "pf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+------------------------------------------+-----------------------+------------+------------+\n",
      "|     Type    | No.of.classes |                Class Id's                |       Class Data      | Total_Data | ~% of Data |\n",
      "+-------------+---------------+------------------------------------------+-----------------------+------------+------------+\n",
      "|  one class  |       4       |           [[1], [2], [3], [4]]           | [769, 195, 4759, 516] |    6239    |   49.641   |\n",
      "|  two class  |       5       | [[1, 2], [1, 3], [2, 3], [2, 4], [3, 4]] |  [35, 91, 14, 1, 284] |    425     |   3.3816   |\n",
      "| Three class |       1       |               [[1, 2, 3]]                |           2           |     2      |   0.0159   |\n",
      "|  four class |       0       |                   nan                    |          nan          |     0      |    0.0     |\n",
      "+-------------+---------------+------------------------------------------+-----------------------+------------+------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "table=PrettyTable()\n",
    "table.field_names =[\"Type\", \"No.of.classes\",\"Class Id's\",\"Class Data\",'Total_Data','~% of Data']\n",
    "table.add_row(['one class',4,[[1],[2],[3],[4]],list(pf['class_count'].values),len(class_1),float(str(len(class_1)*100/(len(df)/4))[:6]) ])\n",
    "t=(multi_class.count([1,2])+multi_class.count([1,3])+multi_class.count([2,3])+multi_class.count([2,4])+multi_class.count([3,4]))\n",
    "table.add_row(['two class',5,[[1,2],[1,3],[2,3],[2,4],[3,4]],[multi_class.count([1,2]),multi_class.count([1,3]),multi_class.count([2,3]),multi_class.count([2,4]),multi_class.count([3,4])],t,float(str((t*100/(len(df)/4)))[:6])])\n",
    "table.add_row(['Three class',1,[[1,2,3]],len(class_3), len(class_3),float(str(len(class_3)*100/(len(df)/4))[:6])])\n",
    "table.add_row(['four class',0,np.nan,np.nan, len(class_4),float(str(len(class_4)*100/(len(df)/4))[:6])])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12568, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageid</th>\n",
       "      <th>binary_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10508</th>\n",
       "      <td>351077c4c.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32092</th>\n",
       "      <td>a345caa40.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50256</th>\n",
       "      <td>fff02e9c5.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36152</th>\n",
       "      <td>b6e3b8a8c.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5364</th>\n",
       "      <td>1b213d816.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             imageid binary_class\n",
       "10508  351077c4c.jpg            0\n",
       "32092  a345caa40.jpg            1\n",
       "50256  fff02e9c5.jpg            1\n",
       "36152  b6e3b8a8c.jpg            0\n",
       "5364   1b213d816.jpg            1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id0=df.iloc[no_class, [2]]\n",
    "id1=df.iloc[class_list,[2]]\n",
    "id0['binary_class']=[0]*len(id0)\n",
    "\n",
    "id1['binary_class']=[1]*len(id1)\n",
    "df_binary=sklearn.utils.shuffle(pd.concat([id0,id1], axis=0))\n",
    "df_binary['binary_class']=df_binary['binary_class'].astype(str)\n",
    "print(df_binary.shape)\n",
    "df_binary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5902, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageid</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>class3</th>\n",
       "      <th>class4</th>\n",
       "      <th>any_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00031f466.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>000418bfc.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>000789191.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>001982b08.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>001d1b355.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          imageid  class1  class2  class3  class4 any_class\n",
       "4   00031f466.jpg       0       0       0       0         0\n",
       "8   000418bfc.jpg       0       0       0       0         0\n",
       "12  000789191.jpg       0       0       0       0         0\n",
       "32  001982b08.jpg       0       0       0       0         0\n",
       "36  001d1b355.jpg       0       0       0       0         0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0=df.iloc[no_class, [2]]\n",
    "df0['class1']=[0]*len(id0)\n",
    "df0['class2']=[0]*len(id0)\n",
    "df0['class3']=[0]*len(id0)\n",
    "df0['class4']=[0]*len(id0)\n",
    "df0['any_class']=['0']*len(id0)\n",
    "print(df0.shape)\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12568, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageid</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>class3</th>\n",
       "      <th>class4</th>\n",
       "      <th>any_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002cc93b.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0007a71bf.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>000a4bcdd.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>000f6bf48.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0014fce06.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          imageid  class1  class2  class3  class4 any_class\n",
       "0   0002cc93b.jpg       1       0       0       0         1\n",
       "16  0007a71bf.jpg       0       0       1       0         1\n",
       "20  000a4bcdd.jpg       1       0       0       0         1\n",
       "24  000f6bf48.jpg       0       0       0       1         1\n",
       "28  0014fce06.jpg       0       0       1       0         1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mid=df.iloc[class_list,[2]]\n",
    "columns =['class1','class2','class3','class4']\n",
    "mulc=pd.DataFrame(m_class,columns =columns,index=mid.index)\n",
    "mulc['any_class']=[1]*len(mulc)\n",
    "mulc=pd.concat([mid,mulc], axis=1)\n",
    "mc=pd.concat([mulc,df0], axis=0)\n",
    "print(mc.shape)\n",
    "mc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6666\n",
       "0    5902\n",
       "Name: any_class, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc['any_class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n",
    "                 base_path='../input/severstal-steel-defect-detection/train_images',\n",
    "                 batch_size=16, dim=(128, 800),preprocess=None, n_channels=3,\n",
    "                 n_classes=1, random_state=2019, shuffle=False):\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.df = df\n",
    "        self.mode = mode\n",
    "        self.preprocess = preprocess\n",
    "        self.base_path = base_path\n",
    "        self.target_df = target_df\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        #print(indexes)\n",
    "        # Find list of IDs\n",
    "        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n",
    "        \n",
    "        X = self.__generate_X(list_IDs_batch)\n",
    "        \n",
    "            \n",
    "        if self.mode == 'fit':\n",
    "            y = self.__generate_y(list_IDs_batch)\n",
    "            return X, y\n",
    "        \n",
    "        elif self.mode == 'predict':\n",
    "            return X\n",
    "\n",
    "        else:\n",
    "            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.seed(self.random_state)\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __generate_X(self, list_IDs_batch):\n",
    "        'Generates data containing batch_size samples'\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        \n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_batch):\n",
    "            #print(i,ID)\n",
    "            im_name = self.df['imageid'][ID]\n",
    "            img_path = f\"{self.base_path}/{im_name}\"\n",
    "            img = self.__load_rgb(img_path)\n",
    "            #print(im_name,img_path)\n",
    "            # Store samples\n",
    "            img = cv2.resize(img,(800,128))\n",
    "            X[i,] = img \n",
    "            #print(\" X sahpe\",X.shape)\n",
    "            #print(\" img sahpe\",img.shape)\n",
    "            # normalize \n",
    "            #X = X / 255\n",
    "        if self.preprocess!=None: X = self.preprocess(X)\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def __generate_y(self, list_IDs_batch):\n",
    "        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n",
    "        \n",
    "        for i, ID in enumerate(list_IDs_batch):\n",
    "            im_name = self.df['imageid'][ID]\n",
    "            #image_df = self.target_df[self.target_df['imageid'] == im_name]\n",
    "            \n",
    "            rles = self.df['EncodedPixels'][ID]\n",
    "            h,w=self.dim\n",
    "            masks = rle_to_mask(rles, 256,1600)\n",
    "            masks = cv2.resize(masks,(800,128))\n",
    "\n",
    "            #print(\" y sahpe\",y.shape)\n",
    "            #print(\" masks sahpe\",masks.shape)\n",
    "            y[i, ] = np.expand_dims(masks, -1)\n",
    "            y = (y > 0).astype(int)\n",
    "        return y \n",
    "\n",
    "        \n",
    "    \n",
    "    def __load_rgb(self, img_path):\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.astype(np.float32) / 255.\n",
    "\n",
    "        return img\n",
    "    \n",
    "    def __load_grayscale(self, img_path):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = img.astype(np.float32) / 255.\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "#https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
    "#Recall shall be the model metric we use to select our best model when there is a high cost associated with False Negative.\n",
    "#TPR\n",
    "def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##  mask pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of dataframe: (7095, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageid</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>class</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>class3</th>\n",
       "      <th>class4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002cc93b.jpg</td>\n",
       "      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0007a71bf.jpg</td>\n",
       "      <td>18661 28 18863 82 19091 110 19347 110 19603 11...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>000a4bcdd.jpg</td>\n",
       "      <td>37607 3 37858 8 38108 14 38359 20 38610 25 388...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>000f6bf48.jpg</td>\n",
       "      <td>131973 1 132228 4 132483 6 132738 8 132993 11 ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0014fce06.jpg</td>\n",
       "      <td>229501 11 229741 33 229981 55 230221 77 230468...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          imageid                                      EncodedPixels class  \\\n",
       "0   0002cc93b.jpg  29102 12 29346 24 29602 24 29858 24 30114 24 3...     1   \n",
       "18  0007a71bf.jpg  18661 28 18863 82 19091 110 19347 110 19603 11...     3   \n",
       "20  000a4bcdd.jpg  37607 3 37858 8 38108 14 38359 20 38610 25 388...     1   \n",
       "27  000f6bf48.jpg  131973 1 132228 4 132483 6 132738 8 132993 11 ...     4   \n",
       "30  0014fce06.jpg  229501 11 229741 33 229981 55 230221 77 230468...     3   \n",
       "\n",
       "    class1  class2  class3  class4  \n",
       "0        1       0       0       0  \n",
       "18       0       0       1       0  \n",
       "20       1       0       0       0  \n",
       "27       0       0       0       1  \n",
       "30       0       0       1       0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This dataframe is for prediction\n",
    "nf=df[['imageid','EncodedPixels','class']][df['EncodedPixels']!=0]\n",
    "nf['class1']=nf['class'].apply(lambda c:1 if int(c)==1 else 0)\n",
    "nf['class2']=nf['class'].apply(lambda c:1 if int(c)==2 else 0)\n",
    "nf['class3']=nf['class'].apply(lambda c:1 if int(c)==3 else 0)\n",
    "nf['class4']=nf['class'].apply(lambda c:1 if int(c)==4 else 0)\n",
    "print(\"shape of dataframe:\",nf.shape)\n",
    "nf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class1 data shape (897, 7)\n",
      "Class2 data shape (247, 7)\n",
      "Class3 data shape (5150, 7)\n",
      "Class4 data shape (801, 7)\n"
     ]
    }
   ],
   "source": [
    "c1=nf[nf['class1']!=0]\n",
    "c2=nf[nf['class2']!=0]\n",
    "c3=nf[nf['class3']!=0]\n",
    "c4=nf[nf['class4']!=0]\n",
    "print(\"Class1 data shape\",c1.shape)\n",
    "print(\"Class2 data shape\",c2.shape)\n",
    "print(\"Class3 data shape\",c3.shape)\n",
    "print(\"Class4 data shape\",c4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting segmentation-models\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/bf/253c8834014a834cacf2384c72872167fb30ccae7a56c6ce46285b03245c/segmentation_models-0.2.1-py2.py3-none-any.whl (44kB)\r\n",
      "\u001b[K     || 51kB 2.0MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: keras>=2.2.0 in /opt/conda/lib/python3.6/site-packages (from segmentation-models) (2.2.4)\r\n",
      "Requirement already satisfied: keras-applications>=1.0.7 in /opt/conda/lib/python3.6/site-packages (from segmentation-models) (1.0.8)\r\n",
      "Collecting image-classifiers==0.2.0 (from segmentation-models)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/32/a1e74e03f74506d1e4b46bb2732ca5a7b18ac52a36b5e3547e63537ce74c/image_classifiers-0.2.0-py2.py3-none-any.whl (76kB)\r\n",
      "\u001b[K     || 81kB 6.1MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: scikit-image in /opt/conda/lib/python3.6/site-packages (from segmentation-models) (0.15.0)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras>=2.2.0->segmentation-models) (1.1.0)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras>=2.2.0->segmentation-models) (2.9.0)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras>=2.2.0->segmentation-models) (1.17.0)\r\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras>=2.2.0->segmentation-models) (1.2.1)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras>=2.2.0->segmentation-models) (5.1.2)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras>=2.2.0->segmentation-models) (1.12.0)\r\n",
      "Requirement already satisfied: imageio>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from scikit-image->segmentation-models) (2.5.0)\r\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->segmentation-models) (3.0.3)\r\n",
      "Requirement already satisfied: pillow>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->segmentation-models) (5.4.1)\r\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->segmentation-models) (2.3)\r\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->segmentation-models) (1.0.3)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->segmentation-models) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->segmentation-models) (1.1.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->segmentation-models) (2.4.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->segmentation-models) (2.8.0)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from networkx>=2.0->scikit-image->segmentation-models) (4.4.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->segmentation-models) (41.0.1)\r\n",
      "Installing collected packages: image-classifiers, segmentation-models\r\n",
      "Successfully installed image-classifiers-0.2.0 segmentation-models-0.2.1\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install segmentation-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/classification_models/resnext/__init__.py:4: UserWarning: Current ResNext models are deprecated, use keras.applications ResNeXt models\n",
      "  warnings.warn('Current ResNext models are deprecated, '\n"
     ]
    }
   ],
   "source": [
    "from segmentation_models import Unet\n",
    "from segmentation_models.backbones import get_preprocessing\n",
    "#model = Unet('resnet34')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-33fbe0880974>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "for i,layer in enumerate(model.layers):\n",
    "    print(i,layer.name)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD UNET WITH PRETRAINING FROM IMAGENET\n",
    "preprocess = get_preprocessing('resnet50') # for resnet, img = (img-110.0)/1.0\n",
    "#model = Unet('resnet34', input_shape=(128, 800, 3), classes=1, activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_to_mask(rle_string, height, width):\n",
    "    \n",
    "    rows, cols = height, width\n",
    "    img = np.zeros(rows * cols, dtype=np.uint8)\n",
    "    if len(str(rle_string)) > 1:\n",
    "        rle_numbers = [int(numstring) for numstring in rle_string.split(' ')]\n",
    "        rle_pairs = np.array(rle_numbers).reshape(-1, 2)\n",
    "        for index, length in rle_pairs:\n",
    "            index -= 1\n",
    "            img[index:index+length] = 255\n",
    "    else: img = np.zeros(cols*rows)\n",
    "    img = img.reshape(cols, rows)\n",
    "    img = img.T\n",
    "    return img\n",
    "\n",
    "\n",
    "def mask_to_rle(mask):\n",
    "    '''\n",
    "    Convert a mask into RLE\n",
    "    \n",
    "    Parameters: \n",
    "    mask (numpy.array): binary mask of numpy array where 1 - mask, 0 - background\n",
    "\n",
    "    Returns: \n",
    "    sring: run length encoding \n",
    "    '''\n",
    "    pixels= mask.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'metric and loss function for evaluation'\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2 * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def loss_dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return -K.log((2 * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(BATCH_SIZE,index_df,dff,dimn):\n",
    "    \n",
    "    train_idx, val_idx = train_test_split(\n",
    "    index_df.index,  # Index matters for each prediction class\n",
    "    random_state=2019, \n",
    "    test_size=0.15)\n",
    "\n",
    "    train_generator = DataGenerator(\n",
    "        train_idx, \n",
    "        df=dff,\n",
    "        dim=dimn,\n",
    "        batch_size=BATCH_SIZE, \n",
    "        n_classes=1)\n",
    "\n",
    "    val_generator = DataGenerator(\n",
    "        val_idx, \n",
    "        df=nf,\n",
    "        dim=dimn,\n",
    "        batch_size=BATCH_SIZE, \n",
    "        n_classes=1)\n",
    "    \n",
    "    \n",
    "    return train_generator,val_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "trainc1,valc1=load(32,c1,nf,dimn=(128,800))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD UNET WITH PRETRAINING FROM IMAGENET\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet50_imagenet_1000_no_top.h5\n",
      "94593024/94592056 [==============================] - 7s 0us/step\n"
     ]
    }
   ],
   "source": [
    "pred_c1 = Unet('resnet50', input_shape=(128, 800, 3), classes=1, activation='sigmoid')\n",
    "pred_c1.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef,loss_dice_coef])\n",
    "#pred_c1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "23/23 [==============================] - 42s 2s/step - loss: 0.5249 - dice_coef: 0.0253 - loss_dice_coef: 3.6829 - val_loss: 0.9976 - val_dice_coef: 0.0187 - val_loss_dice_coef: 3.9930\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 17s 747ms/step - loss: 0.1964 - dice_coef: 0.0310 - loss_dice_coef: 3.4886 - val_loss: 0.2413 - val_dice_coef: 0.0338 - val_loss_dice_coef: 3.3926\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 18s 792ms/step - loss: 0.0983 - dice_coef: 0.0758 - loss_dice_coef: 2.6078 - val_loss: 0.0893 - val_dice_coef: 0.0799 - val_loss_dice_coef: 2.5289\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 18s 790ms/step - loss: 0.0621 - dice_coef: 0.1443 - loss_dice_coef: 1.9520 - val_loss: 0.0537 - val_dice_coef: 0.1233 - val_loss_dice_coef: 2.0942\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 18s 794ms/step - loss: 0.0463 - dice_coef: 0.2115 - loss_dice_coef: 1.5598 - val_loss: 0.0452 - val_dice_coef: 0.1497 - val_loss_dice_coef: 1.9009\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 18s 793ms/step - loss: 0.0367 - dice_coef: 0.2869 - loss_dice_coef: 1.2529 - val_loss: 0.0414 - val_dice_coef: 0.1557 - val_loss_dice_coef: 1.8620\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 18s 794ms/step - loss: 0.0312 - dice_coef: 0.3414 - loss_dice_coef: 1.0780 - val_loss: 0.0433 - val_dice_coef: 0.1215 - val_loss_dice_coef: 2.1135\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 19s 808ms/step - loss: 0.0267 - dice_coef: 0.3984 - loss_dice_coef: 0.9213 - val_loss: 0.0456 - val_dice_coef: 0.0870 - val_loss_dice_coef: 2.4490\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 18s 792ms/step - loss: 0.0237 - dice_coef: 0.4448 - loss_dice_coef: 0.8111 - val_loss: 0.0462 - val_dice_coef: 0.1072 - val_loss_dice_coef: 2.2420\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 20s 860ms/step - loss: 0.0211 - dice_coef: 0.4867 - loss_dice_coef: 0.7212 - val_loss: 0.0399 - val_dice_coef: 0.1544 - val_loss_dice_coef: 1.8705\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 18s 786ms/step - loss: 0.0191 - dice_coef: 0.5269 - loss_dice_coef: 0.6418 - val_loss: 0.0474 - val_dice_coef: 0.0807 - val_loss_dice_coef: 2.5260\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 20s 862ms/step - loss: 0.0177 - dice_coef: 0.5541 - loss_dice_coef: 0.5913 - val_loss: 0.0383 - val_dice_coef: 0.2287 - val_loss_dice_coef: 1.4978\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 20s 883ms/step - loss: 0.0166 - dice_coef: 0.5770 - loss_dice_coef: 0.5505 - val_loss: 0.0394 - val_dice_coef: 0.2402 - val_loss_dice_coef: 1.4332\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - 20s 879ms/step - loss: 0.0148 - dice_coef: 0.6149 - loss_dice_coef: 0.4867 - val_loss: 0.0437 - val_dice_coef: 0.1794 - val_loss_dice_coef: 1.7264\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - 18s 788ms/step - loss: 0.0138 - dice_coef: 0.6376 - loss_dice_coef: 0.4503 - val_loss: 0.0348 - val_dice_coef: 0.3220 - val_loss_dice_coef: 1.1365\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - 18s 785ms/step - loss: 0.0121 - dice_coef: 0.6749 - loss_dice_coef: 0.3934 - val_loss: 0.0406 - val_dice_coef: 0.2202 - val_loss_dice_coef: 1.5220\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - 20s 857ms/step - loss: 0.0114 - dice_coef: 0.6927 - loss_dice_coef: 0.3673 - val_loss: 0.0318 - val_dice_coef: 0.3942 - val_loss_dice_coef: 0.9319\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - 18s 784ms/step - loss: 0.0105 - dice_coef: 0.7160 - loss_dice_coef: 0.3343 - val_loss: 0.0362 - val_dice_coef: 0.3271 - val_loss_dice_coef: 1.1244\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - 18s 792ms/step - loss: 0.0105 - dice_coef: 0.7192 - loss_dice_coef: 0.3298 - val_loss: 0.0332 - val_dice_coef: 0.3668 - val_loss_dice_coef: 1.0052\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - 20s 869ms/step - loss: 0.0105 - dice_coef: 0.7239 - loss_dice_coef: 0.3242 - val_loss: 0.1658 - val_dice_coef: 1.2515e-04 - val_loss_dice_coef: 9.5113\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - 18s 793ms/step - loss: 0.0121 - dice_coef: 0.6820 - loss_dice_coef: 0.3832 - val_loss: 0.1831 - val_dice_coef: 0.0099 - val_loss_dice_coef: 4.8263\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - 18s 783ms/step - loss: 0.0102 - dice_coef: 0.7278 - loss_dice_coef: 0.3179 - val_loss: 0.0612 - val_dice_coef: 0.3961 - val_loss_dice_coef: 0.9282\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - 20s 876ms/step - loss: 0.0098 - dice_coef: 0.7383 - loss_dice_coef: 0.3036 - val_loss: 0.0299 - val_dice_coef: 0.4584 - val_loss_dice_coef: 0.7807\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - 21s 898ms/step - loss: 0.0084 - dice_coef: 0.7713 - loss_dice_coef: 0.2598 - val_loss: 0.0323 - val_dice_coef: 0.4393 - val_loss_dice_coef: 0.8233\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - 18s 789ms/step - loss: 0.0076 - dice_coef: 0.7916 - loss_dice_coef: 0.2339 - val_loss: 0.0307 - val_dice_coef: 0.4731 - val_loss_dice_coef: 0.7500\n"
     ]
    }
   ],
   "source": [
    "#fit data gen\n",
    "history = pred_c1.fit_generator(\n",
    "    trainc1,\n",
    "    validation_data=valc1,\n",
    "    use_multiprocessing=False,\n",
    "    workers=1,\n",
    "    epochs=25 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_c1.save_weights('r50_c1_weights')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "pred_c1.save(\"mod_r50_c1.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "trainc2,valc2=load(32,c2,nf,dimn=(128,800))\n",
    "pred_c2 = Unet('resnet50', input_shape=(128, 800, 3), classes=1, activation='sigmoid')\n",
    "pred_c2.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef,loss_dice_coef])\n",
    "#pred_c2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "6/6 [==============================] - 24s 4s/step - loss: 0.6152 - dice_coef: 0.0214 - loss_dice_coef: 3.8484 - val_loss: 1.6163 - val_dice_coef: 0.0218 - val_loss_dice_coef: 3.8254\n",
      "Epoch 2/25\n",
      "6/6 [==============================] - 5s 765ms/step - loss: 0.3633 - dice_coef: 0.0211 - loss_dice_coef: 3.8592 - val_loss: 0.3743 - val_dice_coef: 0.0123 - val_loss_dice_coef: 4.3947\n",
      "Epoch 3/25\n",
      "6/6 [==============================] - 5s 851ms/step - loss: 0.2776 - dice_coef: 0.0203 - loss_dice_coef: 3.8998 - val_loss: 0.2135 - val_dice_coef: 0.0112 - val_loss_dice_coef: 4.4905\n",
      "Epoch 4/25\n",
      "6/6 [==============================] - 5s 829ms/step - loss: 0.2198 - dice_coef: 0.0225 - loss_dice_coef: 3.7963 - val_loss: 0.1961 - val_dice_coef: 0.0166 - val_loss_dice_coef: 4.0992\n",
      "Epoch 5/25\n",
      "6/6 [==============================] - 5s 886ms/step - loss: 0.1779 - dice_coef: 0.0245 - loss_dice_coef: 3.7139 - val_loss: 0.1932 - val_dice_coef: 0.0207 - val_loss_dice_coef: 3.8790\n",
      "Epoch 6/25\n",
      "6/6 [==============================] - 5s 830ms/step - loss: 0.1462 - dice_coef: 0.0278 - loss_dice_coef: 3.5894 - val_loss: 0.1356 - val_dice_coef: 0.0167 - val_loss_dice_coef: 4.0898\n",
      "Epoch 7/25\n",
      "6/6 [==============================] - 5s 864ms/step - loss: 0.1215 - dice_coef: 0.0366 - loss_dice_coef: 3.3351 - val_loss: 0.1069 - val_dice_coef: 0.0151 - val_loss_dice_coef: 4.1957\n",
      "Epoch 8/25\n",
      "6/6 [==============================] - 5s 810ms/step - loss: 0.1017 - dice_coef: 0.0494 - loss_dice_coef: 3.0431 - val_loss: 0.0869 - val_dice_coef: 0.0203 - val_loss_dice_coef: 3.8965\n",
      "Epoch 9/25\n",
      "6/6 [==============================] - 5s 868ms/step - loss: 0.0854 - dice_coef: 0.0654 - loss_dice_coef: 2.7444 - val_loss: 0.0731 - val_dice_coef: 0.0237 - val_loss_dice_coef: 3.7419\n",
      "Epoch 10/25\n",
      "6/6 [==============================] - 5s 819ms/step - loss: 0.0733 - dice_coef: 0.0852 - loss_dice_coef: 2.4729 - val_loss: 0.0669 - val_dice_coef: 0.0282 - val_loss_dice_coef: 3.5682\n",
      "Epoch 11/25\n",
      "6/6 [==============================] - 5s 862ms/step - loss: 0.0652 - dice_coef: 0.1029 - loss_dice_coef: 2.2908 - val_loss: 0.0751 - val_dice_coef: 0.0319 - val_loss_dice_coef: 3.4461\n",
      "Epoch 12/25\n",
      "6/6 [==============================] - 5s 819ms/step - loss: 0.0578 - dice_coef: 0.1187 - loss_dice_coef: 2.1456 - val_loss: 0.0584 - val_dice_coef: 0.0589 - val_loss_dice_coef: 2.8311\n",
      "Epoch 13/25\n",
      "6/6 [==============================] - 5s 853ms/step - loss: 0.0507 - dice_coef: 0.1516 - loss_dice_coef: 1.8872 - val_loss: 0.0506 - val_dice_coef: 0.0551 - val_loss_dice_coef: 2.8990\n",
      "Epoch 14/25\n",
      "6/6 [==============================] - 5s 822ms/step - loss: 0.0456 - dice_coef: 0.1795 - loss_dice_coef: 1.7221 - val_loss: 0.0504 - val_dice_coef: 0.0506 - val_loss_dice_coef: 2.9835\n",
      "Epoch 15/25\n",
      "6/6 [==============================] - 5s 862ms/step - loss: 0.0414 - dice_coef: 0.2137 - loss_dice_coef: 1.5503 - val_loss: 0.0469 - val_dice_coef: 0.0637 - val_loss_dice_coef: 2.7535\n",
      "Epoch 16/25\n",
      "6/6 [==============================] - 5s 810ms/step - loss: 0.0371 - dice_coef: 0.2460 - loss_dice_coef: 1.4038 - val_loss: 0.0490 - val_dice_coef: 0.0638 - val_loss_dice_coef: 2.7523\n",
      "Epoch 17/25\n",
      "6/6 [==============================] - 5s 848ms/step - loss: 0.0340 - dice_coef: 0.2775 - loss_dice_coef: 1.2848 - val_loss: 0.0440 - val_dice_coef: 0.0914 - val_loss_dice_coef: 2.3925\n",
      "Epoch 18/25\n",
      "6/6 [==============================] - 5s 800ms/step - loss: 0.0317 - dice_coef: 0.2993 - loss_dice_coef: 1.2088 - val_loss: 0.0413 - val_dice_coef: 0.1074 - val_loss_dice_coef: 2.2314\n",
      "Epoch 19/25\n",
      "6/6 [==============================] - 5s 843ms/step - loss: 0.0297 - dice_coef: 0.3161 - loss_dice_coef: 1.1583 - val_loss: 0.0390 - val_dice_coef: 0.1173 - val_loss_dice_coef: 2.1429\n",
      "Epoch 20/25\n",
      "6/6 [==============================] - 5s 812ms/step - loss: 0.0267 - dice_coef: 0.3472 - loss_dice_coef: 1.0590 - val_loss: 0.0368 - val_dice_coef: 0.1438 - val_loss_dice_coef: 1.9395\n",
      "Epoch 21/25\n",
      "6/6 [==============================] - 5s 844ms/step - loss: 0.0250 - dice_coef: 0.3733 - loss_dice_coef: 0.9862 - val_loss: 0.0388 - val_dice_coef: 0.1026 - val_loss_dice_coef: 2.2770\n",
      "Epoch 22/25\n",
      "6/6 [==============================] - 5s 813ms/step - loss: 0.0233 - dice_coef: 0.3867 - loss_dice_coef: 0.9507 - val_loss: 0.0356 - val_dice_coef: 0.1592 - val_loss_dice_coef: 1.8377\n",
      "Epoch 23/25\n",
      "6/6 [==============================] - 5s 860ms/step - loss: 0.0216 - dice_coef: 0.4142 - loss_dice_coef: 0.8816 - val_loss: 0.0362 - val_dice_coef: 0.1299 - val_loss_dice_coef: 2.0411\n",
      "Epoch 24/25\n",
      "6/6 [==============================] - 5s 807ms/step - loss: 0.0200 - dice_coef: 0.4359 - loss_dice_coef: 0.8312 - val_loss: 0.0348 - val_dice_coef: 0.1626 - val_loss_dice_coef: 1.8166\n",
      "Epoch 25/25\n",
      "6/6 [==============================] - 5s 842ms/step - loss: 0.0188 - dice_coef: 0.4543 - loss_dice_coef: 0.7898 - val_loss: 0.0326 - val_dice_coef: 0.1764 - val_loss_dice_coef: 1.7351\n"
     ]
    }
   ],
   "source": [
    "#fit data gen\n",
    "history2 = pred_c2.fit_generator(\n",
    "    trainc2,\n",
    "    validation_data=valc2,\n",
    "    use_multiprocessing=False,\n",
    "    workers=1,\n",
    "    epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_c2.save_weights('r50_c2_weights')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred_c2.save(\"mod_r50_c2.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "trainc3,valc3=load(8,c3,nf,dimn=(128,800))\n",
    "pred_c3 = Unet('resnet50', input_shape=(128, 800, 3), classes=1, activation='sigmoid')\n",
    "pred_c3.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef,loss_dice_coef])\n",
    "#pred_c3.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "547/547 [==============================] - 156s 284ms/step - loss: 0.1406 - dice_coef: 0.4088 - loss_dice_coef: 0.9511 - val_loss: 0.1535 - val_dice_coef: 0.4166 - val_loss_dice_coef: 0.9043\n",
      "Epoch 2/30\n",
      "547/547 [==============================] - 135s 247ms/step - loss: 0.1097 - dice_coef: 0.4993 - loss_dice_coef: 0.7074 - val_loss: 0.1051 - val_dice_coef: 0.5076 - val_loss_dice_coef: 0.6924\n",
      "Epoch 3/30\n",
      "547/547 [==============================] - 137s 250ms/step - loss: 0.1028 - dice_coef: 0.5273 - loss_dice_coef: 0.6524 - val_loss: 0.7851 - val_dice_coef: 0.2909 - val_loss_dice_coef: 1.3274\n",
      "Epoch 4/30\n",
      "547/547 [==============================] - 135s 248ms/step - loss: 0.0987 - dice_coef: 0.5423 - loss_dice_coef: 0.6227 - val_loss: 0.1026 - val_dice_coef: 0.5056 - val_loss_dice_coef: 0.6991\n",
      "Epoch 5/30\n",
      "547/547 [==============================] - 137s 250ms/step - loss: 0.0962 - dice_coef: 0.5551 - loss_dice_coef: 0.5995 - val_loss: 0.0993 - val_dice_coef: 0.5639 - val_loss_dice_coef: 0.5827\n",
      "Epoch 6/30\n",
      "547/547 [==============================] - 135s 246ms/step - loss: 0.0905 - dice_coef: 0.5772 - loss_dice_coef: 0.5588 - val_loss: 0.0936 - val_dice_coef: 0.5932 - val_loss_dice_coef: 0.5339\n",
      "Epoch 7/30\n",
      "547/547 [==============================] - 135s 246ms/step - loss: 0.0892 - dice_coef: 0.5843 - loss_dice_coef: 0.5455 - val_loss: 0.0869 - val_dice_coef: 0.5824 - val_loss_dice_coef: 0.5492\n",
      "Epoch 8/30\n",
      "547/547 [==============================] - 135s 246ms/step - loss: 0.0862 - dice_coef: 0.5962 - loss_dice_coef: 0.5252 - val_loss: 0.0897 - val_dice_coef: 0.5857 - val_loss_dice_coef: 0.5443\n",
      "Epoch 9/30\n",
      "547/547 [==============================] - 136s 249ms/step - loss: 0.0843 - dice_coef: 0.6021 - loss_dice_coef: 0.5164 - val_loss: 0.0968 - val_dice_coef: 0.5367 - val_loss_dice_coef: 0.6341\n",
      "Epoch 10/30\n",
      "547/547 [==============================] - 135s 246ms/step - loss: 0.0812 - dice_coef: 0.6151 - loss_dice_coef: 0.4943 - val_loss: 0.0877 - val_dice_coef: 0.6028 - val_loss_dice_coef: 0.5161\n",
      "Epoch 11/30\n",
      "  1/547 [..............................] - ETA: 2:02 - loss: 0.0617 - dice_coef: 0.5749 - loss_dice_coef: 0.5536"
     ]
    }
   ],
   "source": [
    "#fit data gen\n",
    "history3 = pred_c3.fit_generator(\n",
    "    trainc3,\n",
    "    validation_data=valc3,\n",
    "    use_multiprocessing=False,\n",
    "    workers=1,\n",
    "    epochs=30 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_c3.save_weights('r50_c3_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred_c3.save(\"mod_r50_c3.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "trainc4,valc4=load(32,c4,nf,dimn=(128,800))\n",
    "pred_c4 = Unet('resnet50', input_shape=(128, 800, 3), classes=1, activation='sigmoid')\n",
    "pred_c4.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef,loss_dice_coef])\n",
    "#pred_c4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "21/21 [==============================] - 43s 2s/step - loss: 0.4461 - dice_coef: 0.2571 - loss_dice_coef: 1.3783 - val_loss: 0.8721 - val_dice_coef: 0.2592 - val_loss_dice_coef: 1.3533\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 16s 759ms/step - loss: 0.2354 - dice_coef: 0.3740 - loss_dice_coef: 0.9875 - val_loss: 0.9419 - val_dice_coef: 0.3371 - val_loss_dice_coef: 1.0896\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 18s 860ms/step - loss: 0.1577 - dice_coef: 0.4769 - loss_dice_coef: 0.7425 - val_loss: 0.1671 - val_dice_coef: 0.5048 - val_loss_dice_coef: 0.6870\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 17s 833ms/step - loss: 0.1191 - dice_coef: 0.5708 - loss_dice_coef: 0.5625 - val_loss: 0.1589 - val_dice_coef: 0.5420 - val_loss_dice_coef: 0.6170\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 17s 833ms/step - loss: 0.0961 - dice_coef: 0.6430 - loss_dice_coef: 0.4423 - val_loss: 0.1625 - val_dice_coef: 0.5936 - val_loss_dice_coef: 0.5232\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 17s 793ms/step - loss: 0.0853 - dice_coef: 0.6839 - loss_dice_coef: 0.3802 - val_loss: 0.1641 - val_dice_coef: 0.6163 - val_loss_dice_coef: 0.4868\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 17s 827ms/step - loss: 0.0760 - dice_coef: 0.7171 - loss_dice_coef: 0.3330 - val_loss: 0.1424 - val_dice_coef: 0.5742 - val_loss_dice_coef: 0.5576\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 17s 789ms/step - loss: 0.0651 - dice_coef: 0.7586 - loss_dice_coef: 0.2764 - val_loss: 0.2049 - val_dice_coef: 0.4569 - val_loss_dice_coef: 0.7884\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 17s 831ms/step - loss: 0.0613 - dice_coef: 0.7721 - loss_dice_coef: 0.2588 - val_loss: 0.1698 - val_dice_coef: 0.6043 - val_loss_dice_coef: 0.5068\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 17s 798ms/step - loss: 0.0574 - dice_coef: 0.7888 - loss_dice_coef: 0.2374 - val_loss: 0.1644 - val_dice_coef: 0.6418 - val_loss_dice_coef: 0.4462\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 17s 832ms/step - loss: 0.0543 - dice_coef: 0.8008 - loss_dice_coef: 0.2223 - val_loss: 0.1602 - val_dice_coef: 0.6876 - val_loss_dice_coef: 0.3764\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 17s 790ms/step - loss: 0.0485 - dice_coef: 0.8197 - loss_dice_coef: 0.1990 - val_loss: 0.1571 - val_dice_coef: 0.6591 - val_loss_dice_coef: 0.4202\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 17s 826ms/step - loss: 0.0449 - dice_coef: 0.8341 - loss_dice_coef: 0.1815 - val_loss: 0.2034 - val_dice_coef: 0.5730 - val_loss_dice_coef: 0.5656\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 17s 798ms/step - loss: 0.0409 - dice_coef: 0.8486 - loss_dice_coef: 0.1643 - val_loss: 0.1650 - val_dice_coef: 0.6781 - val_loss_dice_coef: 0.3915\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 17s 830ms/step - loss: 0.0378 - dice_coef: 0.8600 - loss_dice_coef: 0.1509 - val_loss: 0.2167 - val_dice_coef: 0.6030 - val_loss_dice_coef: 0.5133\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 17s 799ms/step - loss: 0.0347 - dice_coef: 0.8716 - loss_dice_coef: 0.1375 - val_loss: 0.1549 - val_dice_coef: 0.7227 - val_loss_dice_coef: 0.3263\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 17s 830ms/step - loss: 0.0330 - dice_coef: 0.8782 - loss_dice_coef: 0.1299 - val_loss: 0.1490 - val_dice_coef: 0.7390 - val_loss_dice_coef: 0.3037\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 17s 797ms/step - loss: 0.0317 - dice_coef: 0.8835 - loss_dice_coef: 0.1240 - val_loss: 0.1594 - val_dice_coef: 0.7543 - val_loss_dice_coef: 0.2831\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 17s 826ms/step - loss: 0.0305 - dice_coef: 0.8873 - loss_dice_coef: 0.1197 - val_loss: 0.1699 - val_dice_coef: 0.7132 - val_loss_dice_coef: 0.3398\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 17s 798ms/step - loss: 0.0280 - dice_coef: 0.8971 - loss_dice_coef: 0.1086 - val_loss: 0.1685 - val_dice_coef: 0.7197 - val_loss_dice_coef: 0.3315\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 18s 834ms/step - loss: 0.0264 - dice_coef: 0.9030 - loss_dice_coef: 0.1021 - val_loss: 0.1687 - val_dice_coef: 0.7359 - val_loss_dice_coef: 0.3091\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 17s 795ms/step - loss: 0.0244 - dice_coef: 0.9099 - loss_dice_coef: 0.0945 - val_loss: 0.1683 - val_dice_coef: 0.7286 - val_loss_dice_coef: 0.3187\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 17s 826ms/step - loss: 0.0236 - dice_coef: 0.9133 - loss_dice_coef: 0.0908 - val_loss: 0.2145 - val_dice_coef: 0.6844 - val_loss_dice_coef: 0.3823\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 17s 791ms/step - loss: 0.0221 - dice_coef: 0.9183 - loss_dice_coef: 0.0852 - val_loss: 0.1888 - val_dice_coef: 0.7091 - val_loss_dice_coef: 0.3456\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 17s 824ms/step - loss: 0.0204 - dice_coef: 0.9245 - loss_dice_coef: 0.0786 - val_loss: 0.1834 - val_dice_coef: 0.7218 - val_loss_dice_coef: 0.3285\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 17s 801ms/step - loss: 0.0193 - dice_coef: 0.9291 - loss_dice_coef: 0.0736 - val_loss: 0.1907 - val_dice_coef: 0.7218 - val_loss_dice_coef: 0.3281\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 17s 831ms/step - loss: 0.0206 - dice_coef: 0.9252 - loss_dice_coef: 0.0778 - val_loss: 0.2066 - val_dice_coef: 0.7015 - val_loss_dice_coef: 0.3572\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 17s 798ms/step - loss: 0.0197 - dice_coef: 0.9276 - loss_dice_coef: 0.0751 - val_loss: 0.1723 - val_dice_coef: 0.7483 - val_loss_dice_coef: 0.2914\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 17s 827ms/step - loss: 0.0193 - dice_coef: 0.9299 - loss_dice_coef: 0.0727 - val_loss: 0.2331 - val_dice_coef: 0.6925 - val_loss_dice_coef: 0.3702\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 17s 791ms/step - loss: 0.0184 - dice_coef: 0.9325 - loss_dice_coef: 0.0700 - val_loss: 0.1949 - val_dice_coef: 0.7452 - val_loss_dice_coef: 0.2961\n"
     ]
    }
   ],
   "source": [
    "#fit data gen\n",
    "history4 = pred_c4.fit_generator(\n",
    "    trainc4,\n",
    "    validation_data=valc4,\n",
    "    use_multiprocessing=False,\n",
    "    workers=1,\n",
    "    epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_c4.save_weights('r50_c4_weights')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "pred_c4.save(\"mod_r50_c4.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
