{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sklearn\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization,Input\nfrom keras.layers import Conv1D, Conv2D, MaxPooling2D,Conv2DTranspose,UpSampling2D\nfrom keras import regularizers, optimizers,Sequential\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport cv2\nimport keras\nfrom sklearn.metrics import recall_score\nfrom tensorflow.python.keras import backend as K \nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm, tqdm_notebook\nimport os\n\n\nfrom keras.layers import Dense,GlobalAveragePooling2D\nfrom keras.applications import MobileNet\nfrom keras.preprocessing import image\nfrom keras.applications.mobilenet import preprocess_input\nfrom keras.models import Model,load_model\nfrom keras.optimizers import Adam\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        #print(os.path.join(dirname, filename))\n#        print(dirname)\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('/kaggle/')","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"['lib', 'input', 'config', 'working']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('/kaggle/input')","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"['multi-weights',\n 'inceptionresnetv2',\n 'models-weights',\n 'segmentationmodels',\n 'tta-git',\n 'severstal-steel-defect-detection']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('/kaggle/input/severstal-steel-defect-detection')","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"['sample_submission.csv', 'train.csv', 'train_images', 'test_images']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('/kaggle/input/severstal-steel-defect-detection/')\ndir1='/kaggle/input/severstal-steel-defect-detection/'","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(dir1+'train.csv')","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub=pd.read_csv(dir1+'sample_submission.csv')\nsub['imageid']=sub.ImageId_ClassId.apply(lambda x: x.split('_')[0])\nsub['class']=sub.ImageId_ClassId.apply(lambda x: int(x.split('_')[1]))\nsub['EncodedPixels']=\" \"\nprint(sub.shape)\nsub.head()\n","execution_count":7,"outputs":[{"output_type":"stream","text":"(7204, 4)\n","name":"stdout"},{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"   ImageId_ClassId EncodedPixels        imageid  class\n0  004f40c73.jpg_1                004f40c73.jpg      1\n1  004f40c73.jpg_2                004f40c73.jpg      2\n2  004f40c73.jpg_3                004f40c73.jpg      3\n3  004f40c73.jpg_4                004f40c73.jpg      4\n4  006f39c41.jpg_1                006f39c41.jpg      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId_ClassId</th>\n      <th>EncodedPixels</th>\n      <th>imageid</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>004f40c73.jpg_1</td>\n      <td></td>\n      <td>004f40c73.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>004f40c73.jpg_2</td>\n      <td></td>\n      <td>004f40c73.jpg</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>004f40c73.jpg_3</td>\n      <td></td>\n      <td>004f40c73.jpg</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>004f40c73.jpg_4</td>\n      <td></td>\n      <td>004f40c73.jpg</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>006f39c41.jpg_1</td>\n      <td></td>\n      <td>006f39c41.jpg</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n                 base_path='../input/severstal-steel-defect-detection/train_images',\n                 batch_size=16, dim=(128, 800),preprocess=None, n_channels=3,\n                 n_classes=1, random_state=2019, shuffle=False):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.df = df\n        self.mode = mode\n        self.preprocess = preprocess\n        self.base_path = base_path\n        self.target_df = target_df\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.random_state = random_state\n        self.on_epoch_end()\n    \n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        #print(indexes)\n        # Find list of IDs\n        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n        \n        X = self.__generate_X(list_IDs_batch)\n        \n            \n        if self.mode == 'fit':\n            y = self.__generate_y(list_IDs_batch)\n            return X, y\n        \n        elif self.mode == 'predict':\n            return X\n\n        else:\n            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n        \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.seed(self.random_state)\n            np.random.shuffle(self.indexes)\n    \n    def __generate_X(self, list_IDs_batch):\n        'Generates data containing batch_size samples'\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        \n        # Generate data\n        for i, ID in enumerate(list_IDs_batch):\n            #print(i,ID)\n            im_name = self.df['imageid'][ID]\n            img_path = f\"{self.base_path}/{im_name}\"\n            img = self.__load_rgb(img_path)\n            #print(im_name,img_path)\n            # Store samples\n            img = cv2.resize(img,(self.dim[1],self.dim[0]))\n            X[i,] = img \n            #print(\" X sahpe\",X.shape)\n            #print(\" img sahpe\",img.shape)\n            # normalize \n            #X = X / 255\n        if self.preprocess!=None: X = self.preprocess(X)\n\n        return X\n    \n    def __generate_y(self, list_IDs_batch):\n        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n        \n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['imageid'][ID]\n            #image_df = self.target_df[self.target_df['imageid'] == im_name]\n            \n            rles = self.df['EncodedPixels'][ID]\n            h,w=self.dim\n            masks = rle_to_mask(rles, 256,1600)\n            masks = cv2.resize(masks,(self.dim[1],self.dim[0]))\n\n            #print(\" y sahpe\",y.shape)\n            #print(\" masks sahpe\",masks.shape)\n            y[i, ] = np.expand_dims(masks, -1)\n            y = (y > 0).astype(int)\n        return y \n\n        \n    \n    def __load_rgb(self, img_path):\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = img.astype(np.float32) / 255.\n\n        return img\n    \n    def __load_grayscale(self, img_path):\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = img.astype(np.float32) / 255.\n        img = np.expand_dims(img, axis=-1)\n\n        return img","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"augmentation_gen=ImageDataGenerator(rescale=1./255.,\n                          shear_range=0.1,\n                          rotation_range=60,\n                          brightness_range=[0.6,1.0],\n                          zoom_range=0.1,\n                          channel_shift_range=0.1,\n                          horizontal_flip=True,\n                          vertical_flip=True,\n                          )","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\n#https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n#Recall shall be the model metric we use to select our best model when there is a high cost associated with False Negative.\n#TPR\ndef recall(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives / (possible_positives + K.epsilon())\n        return recall","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def precision(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub0=sub[['imageid','class']][sub['class'].astype(int)==1]\n\nprint(\"shape of df:\",sub0.shape)\nsub0.head()","execution_count":12,"outputs":[{"output_type":"stream","text":"shape of df: (1801, 2)\n","name":"stdout"},{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"          imageid  class\n0   004f40c73.jpg      1\n4   006f39c41.jpg      1\n8   00b7fb703.jpg      1\n12  00bbcd9af.jpg      1\n16  0108ce457.jpg      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>imageid</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>004f40c73.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>006f39c41.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>00b7fb703.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>00bbcd9af.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0108ce457.jpg</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = InceptionResNetV2(weights=None, input_shape=(299,299,3), include_top=False)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=model.output\nx=GlobalAveragePooling2D()(x)\nx=Dense(64,activation='relu')(x) \nout=Dense(4,activation='sigmoid')(x) #final layer 5 clases\n\nmodel_m=Model(inputs=model.input,outputs=out)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_m.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy',precision,recall])\n#model_m.summary()","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_m.load_weights('/kaggle/input/multi-weights/only_multilabel_weights.h5')","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bs=1\ntest_gen_mul = DataGenerator(\n        sub0.index,\n        df=sub0,\n        dim=(299,299),\n        shuffle=False,\n        mode='predict',\n        base_path='../input/severstal-steel-defect-detection/test_images',\n        batch_size=bs,\n        n_classes=1)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#TTA\ntta_steps = 6\nmulti_class= []\nfor val in tqdm_notebook(test_gen_mul):\n    \n    batch_pred = []\n    for i in range(tta_steps):\n        preds = model_m.predict_generator(augmentation_gen.flow(val,batch_size=bs, shuffle=False),steps=1)\n        batch_pred.append(preds)\n    pred = np.mean(batch_pred, axis=0)\n    multi_class.append(pred)","execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=1801), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff19f7d0a692423091952a71df3e6552"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ndef clear(var):\n    del var\n    return gc.collect()","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clear(test_gen_mul),clear(model_m)","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"(120, 0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"multiC=[np.array(v).flatten().tolist() for v in multi_class]\narr=np.array(multiC)\nmulti_frame=pd.DataFrame(arr,columns=['class1','class2','class3','class4'])\nmulti_frame.index=sub0.index\ndf_mul=sub0.join(multi_frame)\ndf_mul['class1']=df_mul['class1'].apply(lambda v:  1 if v >0.5 else 0)\ndf_mul['class2']=df_mul['class2'].apply(lambda v:  1 if v >0.5 else 0)\ndf_mul['class3']=df_mul['class3'].apply(lambda v:  1 if v >0.5 else 0)\ndf_mul['class4']=df_mul['class4'].apply(lambda v:  1 if v >0.5 else 0)\ndf_mul.head()","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"          imageid  class  class1  class2  class3  class4\n0   004f40c73.jpg      1       1       0       0       0\n4   006f39c41.jpg      1       0       0       1       0\n8   00b7fb703.jpg      1       0       0       1       0\n12  00bbcd9af.jpg      1       0       0       1       0\n16  0108ce457.jpg      1       0       0       1       0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>imageid</th>\n      <th>class</th>\n      <th>class1</th>\n      <th>class2</th>\n      <th>class3</th>\n      <th>class4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>004f40c73.jpg</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>006f39c41.jpg</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>00b7fb703.jpg</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>00bbcd9af.jpg</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0108ce457.jpg</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"c1=df_mul[df_mul['class1']==1]\nc2=df_mul[df_mul['class2']==1]\nc3=df_mul[df_mul['class3']==1]\nc4=df_mul[df_mul['class4']==1]","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.path.append(\"../input/tta-git/\")","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tta_wrapper import tta_segmentation","execution_count":24,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ##  Multi Label Classification"},{"metadata":{},"cell_type":"markdown","source":"## Mask Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"def mask_to_rle(mask):\n    '''\n    Convert a mask into RLE\n    \n    Parameters: \n    mask (numpy.array): binary mask of numpy array where 1 - mask, 0 - background\n\n    Returns: \n    sring: run length encoding \n    '''\n    pixels= mask.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rle_to_mask(rle_string, height, width):\n    \n    rows, cols = height, width\n    img = np.zeros(rows * cols, dtype=np.uint8)\n    if len(str(rle_string)) > 1:\n        rle_numbers = [int(numstring) for numstring in rle_string.split(' ')]\n        rle_pairs = np.array(rle_numbers).reshape(-1, 2)\n        for index, length in rle_pairs:\n            index -= 1\n            img[index:index+length] = 255\n    else: img = np.zeros(cols*rows)\n    img = img.reshape(cols, rows)\n    img = img.T\n    return img","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'metric and loss function for evaluation'\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2 * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef loss_dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return -K.log((2 * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))","execution_count":27,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Class1"},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.path.append(\"../input/tta-git/\")\n","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tta_wrapper import tta_segmentation\n","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_model=load_model('/kaggle/input/models-weights/mod_c1.h5',custom_objects={\"loss_dice_coef\":loss_dice_coef,\"dice_coef\":dice_coef})","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_c1=Model(inputs=mask_model.input,outputs=mask_model.output)\npred_c1.load_weights('/kaggle/input/models-weights/c1_weights')\n","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tta_c1 = tta_segmentation(pred_c1, h_flip=True,v_flip=True, h_shift=(-10, 10), merge='mean')","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bs=1\ngenc1 = DataGenerator(\n        c1.index,\n        df=c1,\n        dim=(128,800),\n        shuffle=False,\n        mode='predict',\n        base_path='../input/severstal-steel-defect-detection/test_images',\n        batch_size=bs,\n        n_classes=1)\n","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_mask1=tta_c1.predict_generator(genc1)","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,j in enumerate(c1.index):\n    img=np.squeeze(pred_mask1[i])\n    img = cv2.resize(img, (1600, 256))\n    tmp = np.copy(img)\n    tmp[tmp<0.5] = 0\n    tmp[tmp>0] = 1\n    pred_rle=mask_to_rle(tmp)\n    sub[\"EncodedPixels\"][j]=pred_rle","execution_count":35,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"clear(genc1),clear(tta_c1),clear(pred_c1)","execution_count":36,"outputs":[{"output_type":"execute_result","execution_count":36,"data":{"text/plain":"(0, 0, 0)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Class2"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_c2=Model(inputs=mask_model.input,outputs=mask_model.output)\npred_c2.load_weights('/kaggle/input/models-weights/c2_weights')\ntta_c2 = tta_segmentation(pred_c2, h_flip=True,v_flip=True, h_shift=(-10, 10), merge='mean')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bs=1\ngenc2 = DataGenerator(\n        c2.index,\n        df=c2,\n        dim=(128,800),\n        shuffle=False,\n        mode='predict',\n        base_path='../input/severstal-steel-defect-detection/test_images',\n        batch_size=bs,\n        n_classes=1)\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_mask2=tta_c2.predict_generator(genc2) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,j in enumerate(c2.index):\n    img=np.squeeze(pred_mask2[i])\n    img = cv2.resize(img, (1600, 256))\n    tmp = np.copy(img)\n    tmp[tmp<0.5] = 0\n    tmp[tmp>0] = 1\n    pred_rle=mask_to_rle(tmp)\n    sub[\"EncodedPixels\"][j]=pred_rle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clear(genc2),clear(pred_c2),clear(tta_c2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Class3"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_c3=Model(inputs=mask_model.input,outputs=mask_model.output)\npred_c3.load_weights('/kaggle/input/models-weights/c3_weights')\ntta_c3 = tta_segmentation(pred_c3, h_flip=True,v_flip=True, h_shift=(-10, 10), merge='mean')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bs=1\ngenc3 = DataGenerator(\n        c3.index,\n        df=c3,\n        dim=(128,800),\n        shuffle=False,\n        mode='predict',\n        base_path='../input/severstal-steel-defect-detection/test_images',\n        batch_size=bs,\n        n_classes=1)\n \npred_mask3 = tta_c3.predict_generator(genc3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,j in enumerate( c3.index):\n    img=np.squeeze(pred_mask3[i])\n    img = cv2.resize(img, (1600, 256))\n    tmp = np.copy(img)\n    tmp[tmp<0.5] = 0\n    tmp[tmp>0] = 1\n    pred_rle=mask_to_rle(tmp)\n    sub[\"EncodedPixels\"][j]=pred_rle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clear(genc3),clear(pred_c3),clear(tta_c3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Class4"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_c4=Model(inputs=mask_model.input,outputs=mask_model.output)\npred_c4.load_weights('/kaggle/input/models-weights/c4_weights')\ntta_c4 = tta_segmentation(pred_c4, h_flip=True,v_flip=True, h_shift=(-10, 10), merge='mean')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bs=1\ngenc4 = DataGenerator(\n        c4.index,\n        df=c4,\n        dim=(128,800),\n        shuffle=False,\n        mode='predict',\n        base_path='../input/severstal-steel-defect-detection/test_images',\n        batch_size=bs,\n        n_classes=1)\n \npred_mask4 = tta_c4.predict_generator(genc4)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,j in enumerate(c4.index):\n    img=np.squeeze(pred_mask4[i])\n    img = cv2.resize(img, (1600, 256))\n    tmp = np.copy(img)\n    tmp[tmp<0.5] = 0\n    tmp[tmp>0] = 1\n    pred_rle=mask_to_rle(tmp)\n    sub[\"EncodedPixels\"][j]=pred_rle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"f, axarr = plt.subplots(2,2,figsize=(7, 7))\naxarr[0,0].imshow(np.squeeze(test_preds[k] > 0.5).astype(int))\naxarr[0,1].imshow(np.squeeze(test_preds2[k] > 0.5).astype(int))\naxarr[1,0].imshow(np.squeeze(test_preds3[k] > 0.5).astype(int))\naxarr[1,1].imshow(np.squeeze(test_preds4[k] > 0.5).astype(int))\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"from IPython.display import FileLink\n#FileLink(r'df_name.csv')\nmodel.save(r\"steel_multi_model.h5\")\nFileLink(r\"steel_multi_model.h5\")\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"steel_binary_model.h5\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub[['ImageId_ClassId','EncodedPixels']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":1}